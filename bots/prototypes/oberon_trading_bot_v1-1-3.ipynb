{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio beautifulsoup4 yfinance torch"
      ],
      "metadata": {
        "id": "2aAxxALzQmBk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "wyUsFfiVRsqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOTE: DQN doesn't switch signals. (WIP)\n",
        "Charting and data saving is fully functional. Run `Save Data` before training DQN."
      ],
      "metadata": {
        "id": "o67tmLWjO22Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.patches import Rectangle\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import io\n",
        "from PIL import Image\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# For the DQN portion:\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    import torch.nn.functional as F\n",
        "except ImportError:\n",
        "    print(\"PyTorch not installed. Please install it if you want to run the DQN training tab.\")\n",
        "\n",
        "DEBUG = True\n",
        "def debug_print(msg):\n",
        "    if DEBUG:\n",
        "        print(msg)\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 1) FOMC Dates Scraper\n",
        "# --------------------------------------------------------------------------------\n",
        "def get_fomc_dates(start_date, end_date):\n",
        "    url = \"https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code != 200:\n",
        "            debug_print(f\"Error: Received status code {response.status_code}\")\n",
        "            return []\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        date_objs = []\n",
        "        for text in soup.stripped_strings:\n",
        "            matches = re.findall(r'([A-Za-z]+ \\d{1,2}, \\d{4})', text)\n",
        "            for date_str in matches:\n",
        "                try:\n",
        "                    dt = datetime.strptime(date_str, \"%B %d, %Y\")\n",
        "                    if dt not in date_objs:\n",
        "                        date_objs.append(dt)\n",
        "                except Exception:\n",
        "                    continue\n",
        "        date_objs = sorted(date_objs)\n",
        "        start_dt = pd.to_datetime(start_date)\n",
        "        end_dt = pd.to_datetime(end_date)\n",
        "        filtered_dates = [dt for dt in date_objs if start_dt <= dt <= end_dt]\n",
        "        return filtered_dates\n",
        "    except Exception as e:\n",
        "        debug_print(f\"Error scraping FOMC dates: {e}\")\n",
        "        return []\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 2) Indicator Helper Functions\n",
        "# --------------------------------------------------------------------------------\n",
        "def exp_average(series, period):\n",
        "    return series.ewm(span=period, adjust=False).mean()\n",
        "\n",
        "def wilder_average(series, length):\n",
        "    return series.ewm(alpha=1/length, adjust=False).mean()\n",
        "\n",
        "def weighted_moving_average(series, window):\n",
        "    weights = np.arange(1, window+1)\n",
        "    return series.rolling(window).apply(lambda prices: np.dot(prices, weights)/weights.sum(), raw=True)\n",
        "\n",
        "def t3(source, length=21, vf=0.7):\n",
        "    ema1 = exp_average(source, length)\n",
        "    ema2 = exp_average(ema1, length)\n",
        "    gd1 = ema1*(1+vf) - ema2*vf\n",
        "    ema11 = exp_average(gd1, length)\n",
        "    ema22 = exp_average(ema11, length)\n",
        "    gd2 = ema11*(1+vf) - ema22*vf\n",
        "    ema111 = exp_average(gd2, length)\n",
        "    ema222 = exp_average(ema111, length)\n",
        "    gd3 = ema111*(1+vf) - ema222*vf\n",
        "    return gd3\n",
        "\n",
        "def vwma(series, window, volume):\n",
        "    return (series*volume).rolling(window=window, min_periods=window).sum()/volume.rolling(window=window, min_periods=window).sum()\n",
        "\n",
        "def rsi_function(close, sensitivity, rsiPeriod, rsiBase):\n",
        "    delta = close.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=rsiPeriod, min_periods=rsiPeriod).mean()\n",
        "    avg_loss = loss.rolling(window=rsiPeriod, min_periods=rsiPeriod).mean()\n",
        "    rs = avg_gain/avg_loss\n",
        "    rsi = 100 - (100/(1+rs))\n",
        "    rsi = rsi.fillna(50)\n",
        "    rsi_adj = sensitivity*(rsi-rsiBase)\n",
        "    return rsi_adj.clip(lower=0, upper=20)\n",
        "\n",
        "def download_data(ticker, start_date, end_date):\n",
        "    df = yf.download(ticker, start=pd.to_datetime(start_date), end=pd.to_datetime(end_date))\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [col[0].lower() for col in df.columns]\n",
        "    else:\n",
        "        df.columns = [str(col).lower() for col in df.columns]\n",
        "    return df\n",
        "\n",
        "def compute_bressert(df, n_period=8, r_period=13):\n",
        "    df['Ln'] = df['low'].rolling(window=n_period, min_periods=1).min()\n",
        "    df['Hn'] = df['high'].rolling(window=n_period, min_periods=1).max()\n",
        "    df['Y'] = ((df['close']-df['Ln'])/(df['Hn']-df['Ln']))*100\n",
        "    df['X'] = exp_average(df['Y'], r_period)\n",
        "    df['Lxn'] = df['X'].rolling(window=n_period, min_periods=1).min()\n",
        "    df['Hxn'] = df['X'].rolling(window=n_period, min_periods=1).max()\n",
        "    df['DSS'] = ((df['X']-df['Lxn'])/(df['Hxn']-df['Lxn']))*100\n",
        "    df['DSSb'] = exp_average(df['DSS'], r_period)\n",
        "    df['DSSsignal'] = df['DSSb'].shift(1)\n",
        "    return df\n",
        "\n",
        "def compute_zscore(df, length_m=14):\n",
        "    momentum = df['close']-df['close'].shift(length_m)\n",
        "    avgMomentum = momentum.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=length_m, min_periods=length_m).std().fillna(0)\n",
        "    zScore = (momentum-avgMomentum)/stdDevMomentum\n",
        "    return zScore\n",
        "\n",
        "def compute_zero_lag_macd(source, fastLength=12, slowLength=26, signalLength=9, MacdEmaLength=9, useEma=True, useOldAlgo=False):\n",
        "    if useEma:\n",
        "        ma1 = source.ewm(span=fastLength, adjust=False).mean()\n",
        "        ma2 = ma1.ewm(span=fastLength, adjust=False).mean()\n",
        "    else:\n",
        "        ma1 = source.rolling(window=fastLength, min_periods=fastLength).mean()\n",
        "        ma2 = ma1.rolling(window=fastLength, min_periods=fastLength).mean()\n",
        "    zerolagEMA = (2*ma1)-ma2\n",
        "    if useEma:\n",
        "        mas1 = source.ewm(span=slowLength, adjust=False).mean()\n",
        "        mas2 = mas1.ewm(span=slowLength, adjust=False).mean()\n",
        "    else:\n",
        "        mas1 = source.rolling(window=slowLength, min_periods=slowLength).mean()\n",
        "        mas2 = mas1.rolling(window=slowLength, min_periods=slowLength).mean()\n",
        "    zerolagslowMA = (2*mas1)-mas2\n",
        "    ZeroLagMACD = zerolagEMA-zerolagslowMA\n",
        "    emasig1 = ZeroLagMACD.ewm(span=signalLength, adjust=False).mean()\n",
        "    emasig2 = emasig1.ewm(span=signalLength, adjust=False).mean()\n",
        "    if useOldAlgo:\n",
        "        signal = ZeroLagMACD.rolling(window=signalLength, min_periods=length_m).mean()\n",
        "    else:\n",
        "        signal = (2*emasig1)-emasig2\n",
        "    hist = ZeroLagMACD - signal\n",
        "    upHist = hist.copy()\n",
        "    upHist[hist<=0] = 0\n",
        "    downHist = hist.copy()\n",
        "    downHist[hist>0] = 0\n",
        "    EMALine = ZeroLagMACD.ewm(span=MacdEmaLength, adjust=False).mean()\n",
        "    dotUP = ZeroLagMACD.copy()\n",
        "    dotUP[(ZeroLagMACD.shift(1)>=signal.shift(1))|(ZeroLagMACD<signal)] = np.nan\n",
        "    dotDN = ZeroLagMACD.copy()\n",
        "    dotDN[(ZeroLagMACD.shift(1)<=signal.shift(1))|(ZeroLagMACD>signal)] = np.nan\n",
        "    return {\n",
        "        \"ZeroLagMACD\": ZeroLagMACD,\n",
        "        \"signal\": signal,\n",
        "        \"hist\": hist,\n",
        "        \"upHist\": upHist,\n",
        "        \"downHist\": downHist,\n",
        "        \"EMALine\": EMALine,\n",
        "        \"dotUP\": dotUP,\n",
        "        \"dotDN\": dotDN\n",
        "    }\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 3) Historical Signals Extraction\n",
        "# --------------------------------------------------------------------------------\n",
        "def extract_macd_signals(df, macd_dict, length_m=14):\n",
        "    macd_line = macd_dict[\"ZeroLagMACD\"]\n",
        "    macd_mean = macd_line.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    macd_std = macd_line.rolling(window=length_m, min_periods=length_m).std().replace(0, np.nan)\n",
        "    macd_zscore = (macd_line - macd_mean)/macd_std\n",
        "\n",
        "    signals = []\n",
        "    for i in range(1, len(df)):\n",
        "        if (pd.notna(macd_dict[\"ZeroLagMACD\"].iloc[i]) and\n",
        "            pd.notna(macd_dict[\"signal\"].iloc[i]) and\n",
        "            pd.notna(macd_dict[\"ZeroLagMACD\"].iloc[i-1]) and\n",
        "            pd.notna(macd_dict[\"signal\"].iloc[i-1])):\n",
        "            dt = df.index[i]\n",
        "            if macd_dict[\"ZeroLagMACD\"].iloc[i]>macd_dict[\"signal\"].iloc[i] and macd_dict[\"ZeroLagMACD\"].iloc[i-1]<=macd_dict[\"signal\"].iloc[i-1]:\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"ZeroLagMACD Buy\",\n",
        "                    \"Z-Score\": round(macd_zscore.iloc[i],2) if not pd.isna(macd_zscore.iloc[i]) else None\n",
        "                })\n",
        "            elif macd_dict[\"ZeroLagMACD\"].iloc[i]<macd_dict[\"signal\"].iloc[i] and macd_dict[\"ZeroLagMACD\"].iloc[i-1]>=macd_dict[\"signal\"].iloc[i-1]:\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"ZeroLagMACD Sell\",\n",
        "                    \"Z-Score\": round(macd_zscore.iloc[i],2) if not pd.isna(macd_zscore.iloc[i]) else None\n",
        "                })\n",
        "    signals_df = pd.DataFrame(signals)\n",
        "    if not signals_df.empty:\n",
        "        signals_df[\"Date\"] = pd.to_datetime(signals_df[\"Date\"])\n",
        "        signals_df = signals_df.sort_values(\"Date\", ascending=False)\n",
        "    return signals_df\n",
        "\n",
        "def extract_momentum_signals(df, length_m=14):\n",
        "    momentum = df['close']-df['close'].shift(length_m)\n",
        "    avgMomentum = momentum.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=length_m, min_periods=length_m).std().fillna(0)\n",
        "    zScore = (momentum-avgMomentum)/stdDevMomentum\n",
        "\n",
        "    def grade(x):\n",
        "        if x>=2:\n",
        "            return \"A\"\n",
        "        elif x>=1:\n",
        "            return \"B\"\n",
        "        elif x>=0:\n",
        "            return \"C\"\n",
        "        elif x>=-1:\n",
        "            return \"D\"\n",
        "        elif x>=-2:\n",
        "            return \"E\"\n",
        "        else:\n",
        "            return \"F\"\n",
        "    momentum_grade = zScore.apply(grade)\n",
        "    momentum_direction = momentum.apply(lambda x: \"Increasing\" if x>0 else \"Decreasing\")\n",
        "\n",
        "    momentum_state = []\n",
        "    for i in range(len(momentum)):\n",
        "        if i==0:\n",
        "            momentum_state.append(\"N/A\")\n",
        "        else:\n",
        "            if abs(momentum.iloc[i])<abs(avgMomentum.iloc[i])*0.1:\n",
        "                momentum_state.append(\"Consolidating\")\n",
        "            elif momentum.iloc[i]*momentum.iloc[i-1]<0:\n",
        "                # turning up vs turning down\n",
        "                if momentum.iloc[i]>0:\n",
        "                    momentum_state.append(\"Turning Up\")\n",
        "                else:\n",
        "                    momentum_state.append(\"Turning Down\")\n",
        "            elif (momentum.iloc[i]>0 and (momentum.iloc[i]-momentum.iloc[i-1])<0) or (momentum.iloc[i]<0 and (momentum.iloc[i]-momentum.iloc[i-1])>0):\n",
        "                momentum_state.append(\"Stalling\")\n",
        "            elif momentum.iloc[i]>0:\n",
        "                momentum_state.append(\"Positive Trending\")\n",
        "            else:\n",
        "                momentum_state.append(\"Negative Trending\")\n",
        "    momentum_state = pd.Series(momentum_state, index=df.index)\n",
        "\n",
        "    signals = []\n",
        "    for i in range(1, len(df)):\n",
        "        if momentum_grade.iloc[i]!=momentum_grade.iloc[i-1]:\n",
        "            signals.append({\n",
        "                \"Date\": df.index[i].strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": f\"Momentum Grade Changed to {momentum_grade.iloc[i]}\",\n",
        "                \"Z-Score\": round(zScore.iloc[i],2)\n",
        "            })\n",
        "        if momentum_direction.iloc[i]!=momentum_direction.iloc[i-1]:\n",
        "            signals.append({\n",
        "                \"Date\": df.index[i].strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": f\"Momentum Direction Changed to {momentum_direction.iloc[i]}\",\n",
        "                \"Z-Score\": round(zScore.iloc[i],2)\n",
        "            })\n",
        "        if momentum_state.iloc[i]!=momentum_state.iloc[i-1]:\n",
        "            signals.append({\n",
        "                \"Date\": df.index[i].strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": f\"Momentum State Changed to {momentum_state.iloc[i]}\",\n",
        "                \"Z-Score\": round(zScore.iloc[i],2)\n",
        "            })\n",
        "    signals_df = pd.DataFrame(signals)\n",
        "    if not signals_df.empty:\n",
        "        signals_df[\"Date\"] = pd.to_datetime(signals_df[\"Date\"])\n",
        "        signals_df = signals_df.sort_values(\"Date\", ascending=False)\n",
        "    return signals_df\n",
        "\n",
        "def extract_signals(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX, length_m=14):\n",
        "    signals = []\n",
        "    zScore = compute_zscore(df, length_m)\n",
        "\n",
        "    # ZLMA\n",
        "    for dt in df.index[signalUp_ZLMA.fillna(False)]:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"ZLMA Buy\",\n",
        "            \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    for dt in df.index[signalDn_ZLMA.fillna(False)]:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"ZLMA Sell\",\n",
        "            \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    # RSI\n",
        "    if isinstance(bullPt, pd.Series):\n",
        "        for dt in bullPt.dropna().index:\n",
        "            signals.append({\n",
        "                \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": \"RSI Buy\",\n",
        "                \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "            })\n",
        "    if isinstance(bearPt, pd.Series):\n",
        "        for dt in bearPt.dropna().index:\n",
        "            signals.append({\n",
        "                \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": \"RSI Sell\",\n",
        "                \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "            })\n",
        "    # MCDX\n",
        "    if isinstance(upSig_MCDX, pd.Series):\n",
        "        for dt in upSig_MCDX.dropna().index:\n",
        "            signals.append({\n",
        "                \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": \"MCDX Buy\",\n",
        "                \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "            })\n",
        "    if isinstance(dnSig_MCDX, pd.Series):\n",
        "        for dt in dnSig_MCDX.dropna().index:\n",
        "            signals.append({\n",
        "                \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": \"MCDX Sell\",\n",
        "                \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    # DSS\n",
        "    for i in range(1, len(df)):\n",
        "        if (pd.notna(df['DSSb'].iloc[i]) and pd.notna(df['DSSsignal'].iloc[i]) and\n",
        "            pd.notna(df['DSSb'].iloc[i-1]) and pd.notna(df['DSSsignal'].iloc[i-1])):\n",
        "            if df['DSSb'].iloc[i]>df['DSSsignal'].iloc[i] and df['DSSb'].iloc[i-1]<=df['DSSsignal'].iloc[i-1]:\n",
        "                dt = df.index[i]\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"DSS Buy\",\n",
        "                    \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "                })\n",
        "            elif df['DSSb'].iloc[i]<df['DSSsignal'].iloc[i] and df['DSSb'].iloc[i-1]>=df['DSSsignal'].iloc[i-1]:\n",
        "                dt = df.index[i]\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"DSS Sell\",\n",
        "                    \"Z-Score\": round(zScore.loc[dt],2) if not pd.isna(zScore.loc[dt]) else None\n",
        "                })\n",
        "\n",
        "    signals_df = pd.DataFrame(signals)\n",
        "    if not signals_df.empty:\n",
        "        signals_df[\"Date\"] = pd.to_datetime(signals_df[\"Date\"])\n",
        "        signals_df = signals_df.sort_values(\"Date\", ascending=False)\n",
        "    return signals_df\n",
        "\n",
        "def get_mcdx_status(df, upSig_MCDX, dnSig_MCDX):\n",
        "    # Check last bar first\n",
        "    last = df.index[-1]\n",
        "    if isinstance(upSig_MCDX, pd.Series) and pd.notna(upSig_MCDX.loc[last]):\n",
        "        return \"Buy\"\n",
        "    elif isinstance(dnSig_MCDX, pd.Series) and pd.notna(dnSig_MCDX.loc[last]):\n",
        "        return \"Sell\"\n",
        "    else:\n",
        "        # Search backward for the most recent non-null signal\n",
        "        for i in range(len(df)-1, -1, -1):\n",
        "            if isinstance(upSig_MCDX, pd.Series) and pd.notna(upSig_MCDX.iloc[i]):\n",
        "                return \"Buy\"\n",
        "            elif isinstance(dnSig_MCDX, pd.Series) and pd.notna(dnSig_MCDX.iloc[i]):\n",
        "                return \"Sell\"\n",
        "        # Fallback (should not happen)\n",
        "        return \"Sell\"\n",
        "\n",
        "def get_rsi_status(df, bullPt, bearPt):\n",
        "    last = df.index[-1]\n",
        "    if isinstance(bullPt, pd.Series) and pd.notna(bullPt.loc[last]):\n",
        "        return \"Buy\"\n",
        "    elif isinstance(bearPt, pd.Series) and pd.notna(bearPt.loc[last]):\n",
        "        return \"Sell\"\n",
        "    else:\n",
        "        # Scan backwards for the most recent non-null RSI signal\n",
        "        for i in range(len(df)-1, -1, -1):\n",
        "            if isinstance(bullPt, pd.Series) and pd.notna(bullPt.iloc[i]):\n",
        "                return \"Buy\"\n",
        "            elif isinstance(bearPt, pd.Series) and pd.notna(bearPt.iloc[i]):\n",
        "                return \"Sell\"\n",
        "        # Fallback\n",
        "        return \"Sell\"\n",
        "\n",
        "def extract_current_status(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt,\n",
        "                           upSig_MCDX, dnSig_MCDX, length_m=14, macd_dict=None):\n",
        "    last = df.index[-1]\n",
        "    # ZLMA: Buy if current ZLMA is above trend EMA, else Sell.\n",
        "    zlma_status = \"Buy\" if df['zlma'].iloc[-1] > df['ema_value'].iloc[-1] else \"Sell\"\n",
        "    # RSI: Use the helper to get the most recent RSI signal.\n",
        "    rsi_status = get_rsi_status(df, bullPt, bearPt)\n",
        "    # MCDX: Use the helper for MCDX (see previous fix).\n",
        "    mcdx_status = \"Buy\" if (isinstance(upSig_MCDX, pd.Series) and pd.notna(upSig_MCDX.loc[last])) \\\n",
        "                    else (\"Sell\" if (isinstance(dnSig_MCDX, pd.Series) and pd.notna(dnSig_MCDX.loc[last])) \\\n",
        "                    else \"Sell\")\n",
        "    # DSS remains unchanged.\n",
        "    dss_status = \"Buy\" if df['DSSb'].iloc[-1] > df['DSSsignal'].iloc[-1] else \"Sell\"\n",
        "\n",
        "    zScore = compute_zscore(df, length_m)\n",
        "    current_zscore = round(zScore.iloc[-1], 2)\n",
        "\n",
        "    # Momentum calculations\n",
        "    momentum = df['close'] - df['close'].shift(length_m)\n",
        "    avgMomentum = momentum.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=length_m, min_periods=length_m).std().fillna(0)\n",
        "    zScore_m = (momentum - avgMomentum) / stdDevMomentum\n",
        "\n",
        "    def get_momentum_grade(z):\n",
        "        if z >= 2:\n",
        "            return \"A\"\n",
        "        elif z >= 1:\n",
        "            return \"B\"\n",
        "        elif z >= 0:\n",
        "            return \"C\"\n",
        "        elif z >= -1:\n",
        "            return \"D\"\n",
        "        elif z >= -2:\n",
        "            return \"E\"\n",
        "        else:\n",
        "            return \"F\"\n",
        "    current_momentum_grade = get_momentum_grade(zScore_m.iloc[-1])\n",
        "    if len(df) < 2:\n",
        "        current_momentum_direction = \"N/A\"\n",
        "        current_momentum_state = \"N/A\"\n",
        "    else:\n",
        "        current_momentum_direction = \"Increasing\" if momentum.iloc[-1] > momentum.iloc[-2] else \"Decreasing\"\n",
        "        change = momentum.iloc[-1] - momentum.iloc[-2]\n",
        "        if momentum.iloc[-1] * momentum.iloc[-2] < 0:\n",
        "            current_momentum_state = \"Turning Up\" if momentum.iloc[-1] > 0 else \"Turning Down\"\n",
        "        elif abs(momentum.iloc[-1]) < abs(avgMomentum.iloc[-1]) * 0.1:\n",
        "            current_momentum_state = \"Consolidating\"\n",
        "        elif (momentum.iloc[-1] > 0 and change < 0) or (momentum.iloc[-1] < 0 and change > 0):\n",
        "            current_momentum_state = \"Stalling\"\n",
        "        elif momentum.iloc[-1] > 0:\n",
        "            current_momentum_state = \"Positive Trending\"\n",
        "        else:\n",
        "            current_momentum_state = \"Negative Trending\"\n",
        "\n",
        "    indicators = [\"ZLMA\", \"RSI\", \"MCDX\", \"DSS\", \"Z-Score\",\n",
        "                  \"Momentum Grade\", \"Momentum Direction\", \"Momentum State\"]\n",
        "    signals = [zlma_status, rsi_status, mcdx_status, dss_status, current_zscore,\n",
        "               current_momentum_grade, current_momentum_direction, current_momentum_state]\n",
        "    if macd_dict is not None:\n",
        "        macd_status = \"Buy\" if macd_dict[\"ZeroLagMACD\"].iloc[-1] > macd_dict[\"signal\"].iloc[-1] else \"Sell\"\n",
        "        indicators.append(\"ZeroLagMACD\")\n",
        "        signals.append(macd_status)\n",
        "    return pd.DataFrame({\"Indicator\": indicators, \"Current Signal\": signals})\n",
        "\n",
        "# -----------------------\n",
        "# 4) Seven-Panel Plot\n",
        "# -----------------------\n",
        "def create_seven_panel_plot(df, ticker, start_date, end_date,\n",
        "                            ema_value, zlma, signalUp_ZLMA, signalDn_ZLMA, zlma_color, ema_color,\n",
        "                            rsi_ma_base, rsi_upper_bound, rsi_lower_bound, bullPt, bearPt,\n",
        "                            b_X, b_DSSb, b_DSSsignal,\n",
        "                            hbma, threshold, upSig_MCDX, dnSig_MCDX,\n",
        "                            Dump, DnCandle, PumpCandle, Retest, Banker,\n",
        "                            iv_series, macd_dict, momentum_length=14):\n",
        "    fig, axs = plt.subplots(7,1,sharex=True,figsize=(12,18),\n",
        "                            gridspec_kw={\"height_ratios\":[2,1,1,1,1,1,1]})\n",
        "    fig.suptitle(f\"{ticker} - 7-Panel Chart with Momentum\", fontsize=14)\n",
        "    x_vals = mdates.date2num(df.index.to_pydatetime())\n",
        "\n",
        "    # Panel 1: Price + ZLMA + RSI + Momentum Text\n",
        "    for i in range(len(df)):\n",
        "        o, c, h, l = df['open'].iloc[i], df['close'].iloc[i], df['high'].iloc[i], df['low'].iloc[i]\n",
        "        color = 'green' if c>=o else 'red'\n",
        "        axs[0].plot([x_vals[i], x_vals[i]], [l, h], color=color, linewidth=1, zorder=1)\n",
        "        candle_width = 0.6\n",
        "        axs[0].add_patch(Rectangle((x_vals[i]-candle_width/2, o), candle_width, c-o,\n",
        "                                   facecolor=color, edgecolor=color, zorder=2))\n",
        "    axs[0].plot(df.index, df['EMA_50'],  label=\"EMA 50\",  color='blue',   linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, df['EMA_100'], label=\"EMA 100\", color='orange', linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, df['EMA_200'], label=\"EMA 200\", color='purple', linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, df['EMA_500'], label=\"EMA 500\", color='brown',  linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, ema_value, label=\"EMA (Trend)\", color=ema_color, linewidth=2, zorder=4)\n",
        "    axs[0].plot(df.index, zlma,      label=\"ZLMA\",        color=zlma_color, linewidth=2, zorder=4)\n",
        "    axs[0].fill_between(df.index, zlma, ema_value, where=(zlma>=ema_value), facecolor=\"darkgreen\", alpha=0.3, interpolate=True, zorder=3)\n",
        "    axs[0].fill_between(df.index, zlma, ema_value, where=(zlma<ema_value),  facecolor=\"darkred\",   alpha=0.3, interpolate=True, zorder=3)\n",
        "    axs[0].scatter(df.index, zlma.where(signalUp_ZLMA), color=\"cyan\",    marker=\"o\", s=50, label=\"ZLMA Buy\",  zorder=5)\n",
        "    axs[0].scatter(df.index, zlma.where(signalDn_ZLMA), color=\"magenta\", marker=\"o\", s=50, label=\"ZLMA Sell\", zorder=5)\n",
        "\n",
        "    axs[0].plot(df.index, rsi_ma_base,     label=\"RSI Trail Base\",  color=\"gray\", linestyle=\"--\", linewidth=1)\n",
        "    axs[0].plot(df.index, rsi_upper_bound, label=\"RSI Trail Upper\", color=\"blue\", linewidth=1)\n",
        "    axs[0].plot(df.index, rsi_lower_bound, label=\"RSI Trail Lower\", color=\"red\",  linewidth=1)\n",
        "    if isinstance(bullPt, pd.Series):\n",
        "        axs[0].scatter(df.index, bullPt, color=\"cyan\",    marker=\"^\", s=50, label=\"RSI Buy\",  zorder=6)\n",
        "    if isinstance(bearPt, pd.Series):\n",
        "        axs[0].scatter(df.index, bearPt, color=\"magenta\", marker=\"v\", s=50, label=\"RSI Sell\", zorder=6)\n",
        "    axs[0].fill_between(df.index, rsi_ma_base, rsi_upper_bound, facecolor=\"darkgreen\", alpha=0.2, interpolate=True)\n",
        "    axs[0].fill_between(df.index, rsi_lower_bound, rsi_ma_base, facecolor=\"darkred\",   alpha=0.2, interpolate=True)\n",
        "\n",
        "    fomc_dates = get_fomc_dates(start_date, end_date)\n",
        "    for i, dt in enumerate(fomc_dates):\n",
        "        axs[0].axvline(dt, color=\"purple\", linestyle=\"--\", linewidth=1, label=\"FOMC\" if i==0 else \"\")\n",
        "\n",
        "    axs[0].set_ylabel(\"Price\")\n",
        "    axs[0].legend(loc=\"upper center\", bbox_to_anchor=(0.5,1.15), ncol=5, fontsize=8)\n",
        "\n",
        "    # Momentum text in the top panel\n",
        "    momentum = df['close']-df['close'].shift(momentum_length)\n",
        "    avgMomentum = momentum.rolling(window=momentum_length, min_periods=momentum_length).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=momentum_length, min_periods=momentum_length).std().fillna(0)\n",
        "    zScore_m = (momentum-avgMomentum)/stdDevMomentum\n",
        "    if len(zScore_m.dropna())>0:\n",
        "        last_z = zScore_m.iloc[-1] if stdDevMomentum.iloc[-1]>0 else np.nan\n",
        "    else:\n",
        "        last_z = np.nan\n",
        "    if not np.isnan(last_z):\n",
        "        if last_z>=2:\n",
        "            gradeStr = \"A (Strong Positive Momentum)\"\n",
        "            gradeColor = \"green\"\n",
        "        elif last_z>=1:\n",
        "            gradeStr = \"B (Moderate Positive Momentum)\"\n",
        "            gradeColor = \"mint\"\n",
        "        elif last_z>=0:\n",
        "            gradeStr = \"C (Weak Positive Momentum)\"\n",
        "            gradeColor = \"goldenrod\"\n",
        "        elif last_z>=-1:\n",
        "            gradeStr = \"D (Weak Negative Momentum)\"\n",
        "            gradeColor = \"orange\"\n",
        "        elif last_z>=-2:\n",
        "            gradeStr = \"E (Moderate Negative Momentum)\"\n",
        "            gradeColor = \"red\"\n",
        "        else:\n",
        "            gradeStr = \"F (Strong Negative Momentum)\"\n",
        "            gradeColor = \"darkred\"\n",
        "    else:\n",
        "        gradeStr = \"N/A\"\n",
        "        gradeColor = \"white\"\n",
        "    if len(df)>1:\n",
        "        momentumDirectionIncreasing = (momentum.iloc[-1]>momentum.iloc[-2])\n",
        "        dirStr = \"Increasing\" if momentumDirectionIncreasing else \"Decreasing\"\n",
        "        dirColor = \"green\" if momentumDirectionIncreasing else \"red\"\n",
        "        change = momentum.iloc[-1]-momentum.iloc[-2]\n",
        "        if momentum.iloc[-1]*momentum.iloc[-2]<0:\n",
        "            stateStr = \"Turning Up\" if momentum.iloc[-1]>0 else \"Turning Down\"\n",
        "            stateColor = \"orange\"\n",
        "        elif abs(momentum.iloc[-1])<abs(avgMomentum.iloc[-1])*0.1:\n",
        "            stateStr = \"Consolidating\"\n",
        "            stateColor = \"yellow\"\n",
        "        elif (momentum.iloc[-1]>0 and change<0) or (momentum.iloc[-1]<0 and change>0):\n",
        "            stateStr = \"Stalling\"\n",
        "            stateColor = \"lightgray\"\n",
        "        elif momentum.iloc[-1]>0:\n",
        "            stateStr = \"Positive Trending\"\n",
        "            stateColor = \"green\"\n",
        "        else:\n",
        "            stateStr = \"Negative Trending\"\n",
        "            stateColor = \"red\"\n",
        "    else:\n",
        "        dirStr, dirColor = \"N/A\", \"white\"\n",
        "        stateStr, stateColor = \"N/A\", \"white\"\n",
        "\n",
        "    axs[0].text(0.01,0.95, f\"Momentum Grade: {gradeStr} (Z-Score: {last_z:.2f})\", transform=axs[0].transAxes, fontsize=10, color=gradeColor, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
        "    axs[0].text(0.01,0.90, f\"Momentum Direction: {dirStr}\", transform=axs[0].transAxes, fontsize=10, color=dirColor, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
        "    axs[0].text(0.01,0.85, f\"Momentum State: {stateStr}\", transform=axs[0].transAxes, fontsize=10, color=stateColor, bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
        "\n",
        "    # Panel 2: Bressert\n",
        "    axs[1].plot(df.index, b_X, label=\"X (EMA of Y)\", color=\"black\", linewidth=2)\n",
        "    marker_colors = ['black'] + ['red' if b_X.iloc[i]<b_X.iloc[i-1] else 'green' for i in range(1, len(b_X))]\n",
        "    axs[1].scatter(df.index, b_X, c=marker_colors, s=20)\n",
        "    axs[1].plot(df.index, b_DSSb,       label=\"DSSb\",       color=\"blue\",    linewidth=2)\n",
        "    axs[1].plot(df.index, b_DSSsignal,  label=\"DSSsignal\",  color=\"magenta\", linewidth=2)\n",
        "    axs[1].axhline(50, color=\"gray\", linewidth=1)\n",
        "    axs[1].axhline(80, color=\"red\",  linewidth=2)\n",
        "    axs[1].axhline(20, color=\"green\",linewidth=2)\n",
        "    axs[1].set_ylabel(\"Bressert\")\n",
        "    axs[1].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 3: MCDX HBMA & Signals\n",
        "    axs[2].plot(df.index, hbma, label=\"HBMA\", color=\"black\", linewidth=2, zorder=3)\n",
        "    axs[2].axhline(threshold, color=\"gray\", linestyle=\"--\", label=\"Threshold\", zorder=2)\n",
        "    axs[2].scatter(df.index, upSig_MCDX, color=\"green\", marker=\"o\", s=50, label=\"MCDX Buy\", zorder=4)\n",
        "    axs[2].scatter(df.index, dnSig_MCDX, color=\"red\",   marker=\"o\", s=50, label=\"MCDX Sell\", zorder=4)\n",
        "    axs[2].set_ylabel(\"MCDX HBMA\")\n",
        "    axs[2].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 4: MCDX Bars\n",
        "    axs[3].bar(df.index, Dump,       width=0.8, color=\"red\",      alpha=0.7, label=\"Dump\",        zorder=1)\n",
        "    axs[3].bar(df.index, DnCandle,   width=0.8, color=\"darkgray\", alpha=0.7, label=\"Down Candle\", zorder=1)\n",
        "    axs[3].bar(df.index, PumpCandle, width=0.8, color=\"green\",    alpha=0.7, label=\"Pump Candle\", zorder=1)\n",
        "    axs[3].bar(df.index, Retest,     width=0.8, color=\"darkred\",  alpha=0.7, label=\"Retest\",      zorder=1)\n",
        "    axs[3].bar(df.index, Banker,     width=0.8, color=\"#84AFC9\",  alpha=0.7, label=\"Banker\",      zorder=1)\n",
        "    axs[3].set_ylabel(\"MCDX Bars\")\n",
        "    axs[3].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 5: Enhanced Zero Lag MACD\n",
        "    axs[4].fill_between(df.index, macd_dict[\"ZeroLagMACD\"], macd_dict[\"signal\"],\n",
        "                        where=(macd_dict[\"ZeroLagMACD\"]>=macd_dict[\"signal\"]),\n",
        "                        facecolor=\"green\", alpha=0.3, interpolate=True)\n",
        "    axs[4].fill_between(df.index, macd_dict[\"ZeroLagMACD\"], macd_dict[\"signal\"],\n",
        "                        where=(macd_dict[\"ZeroLagMACD\"]<macd_dict[\"signal\"]),\n",
        "                        facecolor=\"red\", alpha=0.3, interpolate=True)\n",
        "    axs[4].plot(df.index, macd_dict[\"ZeroLagMACD\"], label=\"ZeroLagMACD\", color=\"green\", linewidth=1)\n",
        "    axs[4].plot(df.index, macd_dict[\"signal\"],      label=\"Signal\",      color=\"red\",   linewidth=1)\n",
        "    axs[4].bar(df.index, macd_dict[\"upHist\"]*2,   label=\"Histogram Up\",   color=\"gray\", width=0.8)\n",
        "    axs[4].bar(df.index, macd_dict[\"downHist\"]*2, label=\"Histogram Down\", color=\"red\",  width=0.8)\n",
        "    axs[4].scatter(df.index, macd_dict[\"dotUP\"], color=\"green\", marker=\"o\", s=50, label=\"Dot Up\")\n",
        "    axs[4].scatter(df.index, macd_dict[\"dotDN\"], color=\"red\",   marker=\"o\", s=50, label=\"Dot Down\")\n",
        "    axs[4].set_ylabel(\"ZeroLag MACD\")\n",
        "    axs[4].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 6: Implied Volatility\n",
        "    axs[5].plot(df.index, iv_series, label=\"VIX\", color=\"darkorange\", linewidth=2)\n",
        "    axs[5].set_ylabel(\"IV\")\n",
        "    axs[5].legend(loc=\"lower left\", fontsize=8)\n",
        "    axs[5].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
        "    for tick in axs[5].get_xticklabels():\n",
        "        tick.set_rotation(45)\n",
        "\n",
        "    # Panel 7: Momentum Z-Score\n",
        "    zScore_panel = compute_zscore(df, momentum_length)\n",
        "    axs[6].axhline(0, color=\"gray\", linestyle=\"--\")\n",
        "    axs[6].fill_between(df.index, zScore_panel, 0, where=(zScore_panel>0), facecolor=\"green\", alpha=0.3)\n",
        "    axs[6].fill_between(df.index, zScore_panel, 0, where=(zScore_panel<0), facecolor=\"red\", alpha=0.3)\n",
        "    axs[6].plot(df.index, zScore_panel, label=\"Momentum Z-Score\", color=\"black\", linewidth=1.5)\n",
        "    axs[6].set_ylabel(\"Momentum\")\n",
        "    axs[6].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def figure_to_pil(fig):\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 5) Main Chart-Generating Function + Gradio Interface\n",
        "# --------------------------------------------------------------------------------\n",
        "default_end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "default_start_date = (datetime.now()-timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def generate_plot(ticker=\"SPY\", start_date=default_start_date, end_date=default_end_date, n_period=8, r_period=13):\n",
        "    try:\n",
        "        df = download_data(ticker, start_date, end_date)\n",
        "        if df.empty:\n",
        "            raise gr.Error(f\"No data for {ticker} from {start_date} to {end_date}\")\n",
        "        for col in [\"open\",\"high\",\"low\",\"close\",\"volume\"]:\n",
        "            if col not in df.columns:\n",
        "                raise gr.Error(f\"Missing {col} data for {ticker}\")\n",
        "\n",
        "        # Basic EMAs\n",
        "        df['EMA_50']  = exp_average(df['close'], 50)\n",
        "        df['EMA_100'] = exp_average(df['close'], 100)\n",
        "        df['EMA_200'] = exp_average(df['close'], 200)\n",
        "        df['EMA_500'] = exp_average(df['close'], 500)\n",
        "\n",
        "        # ZLMA\n",
        "        movAvgLength = 15\n",
        "        ema_value = exp_average(df['close'], movAvgLength)\n",
        "        df['ema_value'] = ema_value\n",
        "        correction = df['close'] + (df['close']-ema_value)\n",
        "        zlma = exp_average(correction, movAvgLength)\n",
        "        df['zlma'] = zlma\n",
        "\n",
        "        signalUp_ZLMA = (zlma>ema_value)&(zlma.shift(1)<=ema_value.shift(1))\n",
        "        signalDn_ZLMA = (zlma<ema_value)&(zlma.shift(1)>=ema_value.shift(1))\n",
        "        zlma_color = \"green\" if zlma.iloc[-1]>zlma.iloc[-2] else \"red\"\n",
        "        ema_color  = \"green\" if ema_value.iloc[-1]<zlma.iloc[-1] else \"red\"\n",
        "\n",
        "        # Bressert\n",
        "        df = compute_bressert(df, n_period, r_period)\n",
        "        b_X         = df['X']\n",
        "        b_DSSb      = df['DSSb']\n",
        "        b_DSSsignal = df['DSSsignal']\n",
        "\n",
        "        # MCDX\n",
        "        RSIBaseBanker    = 50;   RSIPeriodBanker    = 50\n",
        "        RSIBaseHotMoney  = 30;   RSIPeriodHotMoney  = 40\n",
        "        SensitivityBanker= 1.5;  SensitivityHotMoney= 0.7\n",
        "        threshold        = 8.5\n",
        "\n",
        "        rsi_Banker  = rsi_function(df['close'], SensitivityBanker,   RSIPeriodBanker,    RSIBaseBanker)\n",
        "        rsi_HotMoney= rsi_function(df['close'], SensitivityHotMoney, RSIPeriodHotMoney, RSIBaseHotMoney)\n",
        "        hot  = rsi_HotMoney\n",
        "        bank = rsi_Banker\n",
        "\n",
        "        hotma2  = wilder_average(hot, 2)\n",
        "        hotma7  = wilder_average(hot, 7)\n",
        "        hotma31 = wilder_average(hot, 31)\n",
        "        hotma   = exp_average((hotma2*34 + hotma7*33 + hotma31*33)/100, 2)\n",
        "\n",
        "        bankma2  = df['close'].rolling(window=2, min_periods=2).mean()\n",
        "        bankma7  = exp_average(bank, 7)\n",
        "        bankma31 = exp_average(bank,31)\n",
        "        bankma   = ((bankma2*70 + bankma7*20 + bankma31*10)/100).rolling(window=2, min_periods=2).mean()\n",
        "        banksignal = wilder_average(bankma, 4)\n",
        "        df['banksignal'] = banksignal\n",
        "\n",
        "        hbAvg = ((hot*10)+(hotma*35)+(wilder_average(hotma,2)*15)+(bankma*35)+(banksignal*5))/100\n",
        "        hbma = vwma(hbAvg, 2, df['volume'])\n",
        "        df['hbma'] = hbma\n",
        "\n",
        "        downtrendsignal = (hotma.shift(1)>=wilder_average(hotma,2).shift(1))&(hotma<wilder_average(hotma,2))\n",
        "        uptrendsignal   = (hotma.shift(1)<=wilder_average(hotma,2).shift(1))&(hotma>wilder_average(hotma,2))\n",
        "        upSig_MCDX = hbma.where(uptrendsignal,   np.nan)\n",
        "        dnSig_MCDX = hbma.where(downtrendsignal, np.nan)\n",
        "\n",
        "        Dump = bank.where(bank<bank.shift(1)/1.75, np.nan)\n",
        "        dnCond = (bank<bank.shift(1))&(bank<bank.shift(2))&(bank.shift(1)<bank.shift(2))& \\\n",
        "                 (bank<bank.shift(3))&(bank<bank.shift(4))&(bank.shift(3)<bank.shift(4))& \\\n",
        "                 (bank.shift(6)>8.5)&(bank<10)\n",
        "        DnCandle   = bank.where(dnCond, np.nan)\n",
        "        PumpCandle = bank.where(bank>hbma, np.nan)\n",
        "        Retest     = bank.where((banksignal>bankma)&(bank>0), np.nan)\n",
        "        Banker     = bank\n",
        "\n",
        "        # RSI \"Trail\"\n",
        "        lookbackPeriod     = 15\n",
        "        atrLength          = 27\n",
        "        atrMultiplier      = 0.1\n",
        "        rsiLowerThreshold  = 40\n",
        "        rsiUpperThreshold  = 60\n",
        "\n",
        "        ohlc4 = (df['open']+df['high']+df['low']+df['close'])/4\n",
        "        rsi_ma_base = t3(ohlc4, length=lookbackPeriod, vf=0.7)\n",
        "        df['rsi_ma_base'] = rsi_ma_base\n",
        "        tr_series = pd.concat([\n",
        "            df['high']-df['low'],\n",
        "            abs(df['high']-df['close'].shift(1)),\n",
        "            abs(df['low']-df['close'].shift(1))\n",
        "        ], axis=1).max(axis=1)\n",
        "        nzTR = tr_series.fillna(df['high']-df['low'])\n",
        "        f_volatility = wilder_average(nzTR, atrLength)*atrMultiplier\n",
        "        rsi_upper_bound = rsi_ma_base+((rsiUpperThreshold-50)/10)*f_volatility\n",
        "        rsi_lower_bound = rsi_ma_base-((50-rsiLowerThreshold)/10)*f_volatility\n",
        "\n",
        "        crossUp = (ohlc4>rsi_upper_bound)&(ohlc4.shift(1)<=rsi_upper_bound.shift(1))\n",
        "        crossDn = (df['close']<rsi_lower_bound)&(df['close'].shift(1)>=rsi_lower_bound.shift(1))\n",
        "        bullPt = rsi_lower_bound.where(crossUp, np.nan)\n",
        "        bearPt = rsi_upper_bound.where(crossDn, np.nan)\n",
        "\n",
        "        # VIX\n",
        "        vix_df = yf.download(\"^VIX\", start=pd.to_datetime(start_date), end=pd.to_datetime(end_date))\n",
        "        if vix_df.empty:\n",
        "            iv_series = pd.Series(np.nan, index=df.index)\n",
        "        else:\n",
        "            vix_df.index = pd.to_datetime(vix_df.index)\n",
        "            iv_series = vix_df[\"Close\"].reindex(df.index, method=\"ffill\")\n",
        "\n",
        "        fomc_dates = get_fomc_dates(start_date, end_date)\n",
        "\n",
        "        # Zero Lag MACD\n",
        "        macd_dict = compute_zero_lag_macd(df['close'], fastLength=12, slowLength=26, signalLength=9,\n",
        "                                          MacdEmaLength=9, useEma=True, useOldAlgo=False)\n",
        "\n",
        "        # Create 7-panel\n",
        "        fig = create_seven_panel_plot(df, ticker, start_date, end_date,\n",
        "                                      ema_value, zlma, signalUp_ZLMA, signalDn_ZLMA, zlma_color, ema_color,\n",
        "                                      rsi_ma_base, rsi_upper_bound, rsi_lower_bound, bullPt, bearPt,\n",
        "                                      b_X, b_DSSb, b_DSSsignal,\n",
        "                                      hbma, threshold, upSig_MCDX, dnSig_MCDX,\n",
        "                                      Dump, DnCandle, PumpCandle, Retest, Banker,\n",
        "                                      iv_series, macd_dict,\n",
        "                                      momentum_length=14)\n",
        "\n",
        "        ax0 = fig.axes[0]\n",
        "        for i, dt in enumerate(fomc_dates):\n",
        "            ax0.axvline(dt, color=\"purple\", linestyle=\"--\", linewidth=1, label=\"FOMC\" if i==0 else \"\")\n",
        "        handles, labels = ax0.get_legend_handles_labels()\n",
        "        unique = dict(zip(labels, handles))\n",
        "        ax0.legend(unique.values(), unique.keys(), loc=\"lower right\", ncol=3, fontsize=8)\n",
        "\n",
        "        # Build historical signals\n",
        "        signals_df = extract_signals(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX, length_m=14)\n",
        "        momentum_signals_df = extract_momentum_signals(df, length_m=14)\n",
        "        macd_signals_df = extract_macd_signals(df, macd_dict, length_m=14)\n",
        "        historical_signals_df = pd.concat([signals_df, momentum_signals_df, macd_signals_df], ignore_index=True)\n",
        "        if not historical_signals_df.empty:\n",
        "            historical_signals_df[\"Date\"] = pd.to_datetime(historical_signals_df[\"Date\"])\n",
        "            historical_signals_df = historical_signals_df.sort_values(\"Date\", ascending=False)\n",
        "\n",
        "        # Current Status\n",
        "        current_status_df = extract_current_status(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt,\n",
        "                                                   upSig_MCDX, dnSig_MCDX, length_m=14, macd_dict=macd_dict)\n",
        "\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "        buf.seek(0)\n",
        "        pil_img = Image.open(buf)\n",
        "        plt.close(fig)\n",
        "\n",
        "        return pil_img, current_status_df, historical_signals_df\n",
        "    except Exception as e:\n",
        "        debug_print(f\"Error: {e}\")\n",
        "        raise gr.Error(f\"An error occurred: {e}\")\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 6) Data Saving\n",
        "# --------------------------------------------------------------------------------\n",
        "def save_historical_data(ticker=\"SPY\", start_date=default_start_date, end_date=default_end_date,\n",
        "                         n_period=8, r_period=13,\n",
        "                         data_filename=\"full_data.csv\", signals_filename=\"signals_data.csv\"):\n",
        "    try:\n",
        "        df = download_data(ticker, start_date, end_date)\n",
        "        if df.empty:\n",
        "            raise gr.Error(f\"No data for {ticker} from {start_date} to {end_date}\")\n",
        "        for col in [\"open\",\"high\",\"low\",\"close\",\"volume\"]:\n",
        "            if col not in df.columns:\n",
        "                raise gr.Error(f\"Missing {col} data for {ticker}\")\n",
        "\n",
        "        # Basic EMAs\n",
        "        df['EMA_50']  = exp_average(df['close'], 50)\n",
        "        df['EMA_100'] = exp_average(df['close'], 100)\n",
        "        df['EMA_200'] = exp_average(df['close'], 200)\n",
        "        df['EMA_500'] = exp_average(df['close'], 500)\n",
        "\n",
        "        # ZLMA\n",
        "        movAvgLength = 15\n",
        "        ema_value = exp_average(df['close'], movAvgLength)\n",
        "        df['ema_value'] = ema_value\n",
        "        correction = df['close']+(df['close']-ema_value)\n",
        "        zlma = exp_average(correction, movAvgLength)\n",
        "        df['zlma'] = zlma\n",
        "\n",
        "        # Bressert\n",
        "        df = compute_bressert(df, n_period, r_period)\n",
        "\n",
        "        # MCDX\n",
        "        RSIBaseBanker     = 50;   RSIPeriodBanker    = 50\n",
        "        RSIBaseHotMoney   = 30;   RSIPeriodHotMoney  = 40\n",
        "        SensitivityBanker = 1.5;  SensitivityHotMoney= 0.7\n",
        "        threshold         = 8.5\n",
        "\n",
        "        rsi_Banker   = rsi_function(df['close'], SensitivityBanker, RSIPeriodBanker, RSIBaseBanker)\n",
        "        rsi_HotMoney = rsi_function(df['close'], SensitivityHotMoney, RSIPeriodHotMoney, RSIBaseHotMoney)\n",
        "        hot  = rsi_HotMoney\n",
        "        bank = rsi_Banker\n",
        "\n",
        "        hotma2  = wilder_average(hot, 2)\n",
        "        hotma7  = wilder_average(hot, 7)\n",
        "        hotma31 = wilder_average(hot, 31)\n",
        "        hotma   = exp_average((hotma2*34 + hotma7*33 + hotma31*33)/100, 2)\n",
        "\n",
        "        bankma2  = df['close'].rolling(window=2, min_periods=2).mean()\n",
        "        bankma7  = exp_average(bank, 7)\n",
        "        bankma31 = exp_average(bank, 31)\n",
        "        bankma   = ((bankma2*70 + bankma7*20 + bankma31*10)/100).rolling(window=2, min_periods=2).mean()\n",
        "        banksignal = wilder_average(bankma, 4)\n",
        "        df['banksignal'] = banksignal\n",
        "\n",
        "        hbAvg = ((hot*10)+(hotma*35)+(wilder_average(hotma,2)*15)+(bankma*35)+(banksignal*5))/100\n",
        "        hbma = vwma(hbAvg, 2, df['volume'])\n",
        "        df['hbma'] = hbma\n",
        "\n",
        "        # Additional columns for historical signals\n",
        "        # We'll just do 0/1 columns for each indicator's buy/sell\n",
        "        # But first let's get the main signals\n",
        "        movAvgLength = 15\n",
        "        df['ema_value'] = exp_average(df['close'], movAvgLength)\n",
        "        correction = df['close']+(df['close']-df['ema_value'])\n",
        "        df['zlma'] = exp_average(correction, movAvgLength)\n",
        "        signalUp_ZLMA = (df['zlma']>df['ema_value'])&(df['zlma'].shift(1)<=df['ema_value'].shift(1))\n",
        "        signalDn_ZLMA = (df['zlma']<df['ema_value'])&(df['zlma'].shift(1)>=df['ema_value'].shift(1))\n",
        "\n",
        "        # RSI trail\n",
        "        lookbackPeriod = 15\n",
        "        atrLength      = 27\n",
        "        atrMultiplier  = 0.1\n",
        "        rsiLowerThreshold = 40\n",
        "        rsiUpperThreshold = 60\n",
        "        ohlc4 = (df['open']+df['high']+df['low']+df['close'])/4\n",
        "        rsi_ma_base = t3(ohlc4, length=lookbackPeriod, vf=0.7)\n",
        "        df['rsi_ma_base'] = rsi_ma_base\n",
        "        tr_series = pd.concat([\n",
        "            df['high']-df['low'],\n",
        "            abs(df['high']-df['close'].shift(1)),\n",
        "            abs(df['low']-df['close'].shift(1))\n",
        "        ], axis=1).max(axis=1)\n",
        "        nzTR = tr_series.fillna(df['high']-df['low'])\n",
        "        f_volatility = wilder_average(nzTR, atrLength)*atrMultiplier\n",
        "        rsi_upper_bound = rsi_ma_base + ((rsiUpperThreshold-50)/10)*f_volatility\n",
        "        rsi_lower_bound = rsi_ma_base - ((50-rsiLowerThreshold)/10)*f_volatility\n",
        "        crossUp = (ohlc4>rsi_upper_bound)&(ohlc4.shift(1)<=rsi_upper_bound.shift(1))\n",
        "        crossDn = (df['close']<rsi_lower_bound)&(df['close'].shift(1)>=rsi_lower_bound.shift(1))\n",
        "        bullPt = rsi_lower_bound.where(crossUp, np.nan)\n",
        "        bearPt = rsi_upper_bound.where(crossDn, np.nan)\n",
        "\n",
        "        uptrendsignal = (hotma.shift(1)<=wilder_average(hotma,2).shift(1))&(hotma>wilder_average(hotma,2))\n",
        "        downtrendsignal= (hotma.shift(1)>=wilder_average(hotma,2).shift(1))&(hotma<wilder_average(hotma,2))\n",
        "        upSig_MCDX = df['hbma'].where(uptrendsignal,   np.nan)\n",
        "        dnSig_MCDX = df['hbma'].where(downtrendsignal, np.nan)\n",
        "\n",
        "        # Now gather signals\n",
        "        from copy import deepcopy\n",
        "        macd_dict = compute_zero_lag_macd(df['close'], fastLength=12, slowLength=26, signalLength=9, MacdEmaLength=9, useEma=True, useOldAlgo=False)\n",
        "        signals_df = extract_signals(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX, length_m=14)\n",
        "        momentum_signals_df = extract_momentum_signals(df, length_m=14)\n",
        "        macd_signals_df = extract_macd_signals(df, macd_dict, length_m=14)\n",
        "        historical_signals_df = pd.concat([signals_df, momentum_signals_df, macd_signals_df], ignore_index=True)\n",
        "        if not historical_signals_df.empty:\n",
        "            historical_signals_df[\"Date\"] = pd.to_datetime(historical_signals_df[\"Date\"])\n",
        "            historical_signals_df = historical_signals_df.sort_values(\"Date\", ascending=False)\n",
        "\n",
        "        # 0/1 columns\n",
        "        indicator_list = [\"ZLMA\",\"RSI\",\"MCDX\",\"DSS\",\"ZeroLagMACD\"]\n",
        "        signals_grouped = historical_signals_df.groupby(\"Date\")[\"Signal\"].apply(list)\n",
        "        for ind in indicator_list:\n",
        "            df[ind+\"_Buy\"] = df.index.to_series().apply(\n",
        "                lambda d: 1 if any((ind in s and \"Buy\" in s) for s in signals_grouped.get(d,[])) else 0\n",
        "            )\n",
        "            df[ind+\"_Sell\"] = df.index.to_series().apply(\n",
        "                lambda d: 1 if any((ind in s and \"Sell\" in s) for s in signals_grouped.get(d,[])) else 0\n",
        "            )\n",
        "\n",
        "        df.to_csv(data_filename)\n",
        "        historical_signals_df.to_csv(signals_filename, index=False)\n",
        "        return f\"Saved {data_filename} and {signals_filename} successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        debug_print(f\"Error: {e}\")\n",
        "        raise gr.Error(f\"An error occurred: {e}\")\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 7) DQN + environment\n",
        "# --------------------------------------------------------------------------------\n",
        "class TradingEnv:\n",
        "    \"\"\"\n",
        "    Minimal environment that references the 0/1 columns from the CSV.\n",
        "    This version is the sliding window environment. You can adjust as needed.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, window_size=3, max_hold_days=10):\n",
        "        self.df = df.reset_index(drop=True).copy()\n",
        "        self.length = len(self.df)\n",
        "        self.window_size = window_size\n",
        "        self.max_hold_days = max_hold_days\n",
        "\n",
        "        self.signal_cols = [\n",
        "            \"ZLMA_Buy\",\"ZLMA_Sell\",\"RSI_Buy\",\"RSI_Sell\",\n",
        "            \"MCDX_Buy\",\"MCDX_Sell\",\"DSS_Buy\",\"DSS_Sell\",\n",
        "            \"ZeroLagMACD_Buy\",\"ZeroLagMACD_Sell\"\n",
        "        ]\n",
        "        for col in self.signal_cols:\n",
        "            if col not in self.df.columns:\n",
        "                self.df[col] = 0\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.position = 0\n",
        "        self.hold_counter = 0\n",
        "        self.history_buffer = []\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.position = 0\n",
        "        self.hold_counter = 0\n",
        "        self.history_buffer = []\n",
        "        for _ in range(self.window_size):\n",
        "            self._append_history()\n",
        "        return self._get_state()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        0=Hold, 1=Go Long, 2=Go Short\n",
        "        \"\"\"\n",
        "        prev_position = self.position\n",
        "        current_price = self.df.loc[self.current_step, 'close']\n",
        "        reward = 0.0\n",
        "        if self.current_step>0:\n",
        "            price_prev = self.df.loc[self.current_step-1, 'close']\n",
        "            reward = (current_price-price_prev)*prev_position\n",
        "\n",
        "        # flipping cost\n",
        "        if (prev_position==1 and action==2) or (prev_position==-1 and action==1):\n",
        "            reward -= 0.001*current_price\n",
        "\n",
        "        new_position = self.position\n",
        "        if action==1:\n",
        "            new_position = 1\n",
        "        elif action==2:\n",
        "            new_position = -1\n",
        "\n",
        "        if new_position!=prev_position:\n",
        "            self.position = new_position\n",
        "            if self.position==0:\n",
        "                self.hold_counter=0\n",
        "            else:\n",
        "                self.hold_counter=1\n",
        "        else:\n",
        "            if self.position!=0:\n",
        "                self.hold_counter+=1\n",
        "\n",
        "        if self.hold_counter>self.max_hold_days:\n",
        "            # forced close\n",
        "            reward -= 0.02*current_price\n",
        "            self.position=0\n",
        "            self.hold_counter=0\n",
        "\n",
        "        # alignment bonus\n",
        "        day_signals = self.df.loc[self.current_step, self.signal_cols].values\n",
        "        buy_sum  = day_signals[0::2].sum()\n",
        "        sell_sum = day_signals[1::2].sum()\n",
        "        if self.position==1:\n",
        "            reward += 0.05*buy_sum\n",
        "            reward -= 0.02*sell_sum\n",
        "        elif self.position==-1:\n",
        "            reward += 0.05*sell_sum\n",
        "            reward -= 0.02*buy_sum\n",
        "\n",
        "        self.current_step+=1\n",
        "        done = (self.current_step>=self.length-1)\n",
        "        self._append_history()\n",
        "\n",
        "        return self._get_state(), reward, done\n",
        "\n",
        "    def _append_history(self):\n",
        "        if self.current_step<self.length:\n",
        "            row = self.df.loc[self.current_step, [\"close\"]+self.signal_cols].values\n",
        "        else:\n",
        "            row = self.df.loc[self.length-1, [\"close\"]+self.signal_cols].values\n",
        "        self.history_buffer.append(row.astype(np.float32))\n",
        "        if len(self.history_buffer)>self.window_size:\n",
        "            self.history_buffer.pop(0)\n",
        "\n",
        "    def _get_state(self):\n",
        "        arr = np.array(self.history_buffer)\n",
        "        flattened = arr.flatten()\n",
        "        return np.concatenate([flattened, [float(self.position)]], dtype=np.float32)\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=34, hidden_dim=64, output_dim=3):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def train_dqn_from_df(df, episodes=5, gamma=0.99, lr=1e-3, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
        "    env = TradingEnv(df, window_size=3, max_hold_days=10)\n",
        "    # input_dim= (3*(1+10))+1= 3*11+1=33+1=34\n",
        "    policy_net = QNetwork(input_dim=34, hidden_dim=64, output_dim=3)\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "    rewards_per_episode = []\n",
        "    for ep in range(episodes):\n",
        "        state = env.reset()\n",
        "        done=False\n",
        "        ep_reward=0.0\n",
        "        while not done:\n",
        "            if np.random.rand()<epsilon:\n",
        "                action = np.random.randint(0,3)\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    s = torch.FloatTensor(state).unsqueeze(0)\n",
        "                    q_values = policy_net(s)\n",
        "                    action = q_values.argmax(dim=1).item()\n",
        "            next_state, reward, done = env.step(action)\n",
        "            ep_reward+=reward\n",
        "\n",
        "            with torch.no_grad():\n",
        "                s_next = torch.FloatTensor(next_state).unsqueeze(0)\n",
        "                next_q_values = policy_net(s_next)\n",
        "                target_value = reward + (0 if done else gamma*next_q_values.max(dim=1)[0].item())\n",
        "\n",
        "            s = torch.FloatTensor(state).unsqueeze(0)\n",
        "            q_values = policy_net(s)\n",
        "            q_current = q_values[0, action]\n",
        "            loss = F.mse_loss(q_current, torch.FloatTensor([target_value]))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            state=next_state\n",
        "        epsilon = max(epsilon_min, epsilon*epsilon_decay)\n",
        "        rewards_per_episode.append({\"Episode\": ep+1, \"Total Reward\": ep_reward})\n",
        "\n",
        "    return pd.DataFrame(rewards_per_episode), policy_net\n",
        "\n",
        "def simulate_dqn_trades(policy_net, df):\n",
        "    \"\"\"\n",
        "    Runs a simulation with the trained policy (greedy) and logs an action every day\n",
        "    (Buy, Sell, or Hold), along with the date and price.\n",
        "    \"\"\"\n",
        "    env = TradingEnv(df)\n",
        "    state = env.reset()\n",
        "    all_actions = []  # We'll store (date, action_name, price) for every day\n",
        "    day_idx = 0\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            s = torch.FloatTensor(state).unsqueeze(0)\n",
        "            q_values = policy_net(s)\n",
        "            action = q_values.argmax(dim=1).item()\n",
        "\n",
        "        # Convert numeric action => text label\n",
        "        if action == 1:\n",
        "            action_name = \"Buy\"\n",
        "        elif action == 2:\n",
        "            action_name = \"Sell\"\n",
        "        else:\n",
        "            action_name = \"Hold\"\n",
        "\n",
        "        if day_idx < len(df):\n",
        "            date_here = df.index[day_idx]\n",
        "            price_here = df.loc[date_here, 'close']\n",
        "            all_actions.append((date_here, action_name, price_here))\n",
        "\n",
        "        next_state, reward, done = env.step(action)\n",
        "        state = next_state\n",
        "        day_idx += 1\n",
        "\n",
        "    return all_actions\n",
        "\n",
        "def plot_trades_chart(df, all_actions):\n",
        "    \"\"\"\n",
        "    Plots a marker for every daily action:\n",
        "      - Green ^ for Buy\n",
        "      - Red v for Sell\n",
        "      - Blue . for Hold\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(df.index, df['close'], label=\"Close Price\")\n",
        "\n",
        "    # We track which legend labels have been used so we don't repeat them\n",
        "    used_labels = set()\n",
        "\n",
        "    for (date, action_name, price) in all_actions:\n",
        "        if action_name == \"Buy\":\n",
        "            marker, color = \"^\", \"green\"\n",
        "        elif action_name == \"Sell\":\n",
        "            marker, color = \"v\", \"red\"\n",
        "        else:  # Hold\n",
        "            marker, color = \".\", \"blue\"\n",
        "\n",
        "        # Only add a legend entry once per action_name\n",
        "        lbl = action_name if action_name not in used_labels else None\n",
        "        used_labels.add(action_name)\n",
        "\n",
        "        ax.scatter(date, price, marker=marker, color=color, s=100, label=lbl)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_title(\"DQN Trades on Price Chart (All Actions Plotted)\")\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    plt.close(fig)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def run_dqn_csv(csv_data_path=\"full_data.csv\", episodes=5):\n",
        "    try:\n",
        "        df = pd.read_csv(csv_data_path, parse_dates=True, index_col=0)\n",
        "        if 'close' not in df.columns:\n",
        "            raise gr.Error(\"No 'close' column in CSV. Please ensure CSV has the necessary columns.\")\n",
        "        # Train the DQN\n",
        "        rewards_df, policy_net = train_dqn_from_df(df, episodes=episodes)\n",
        "\n",
        "        # Simulate day by day, logging every action\n",
        "        all_actions = simulate_dqn_trades(policy_net, df)\n",
        "\n",
        "        # Debug print so you can see all actions in console\n",
        "        print(\"=== DQN Actions Day by Day ===\")\n",
        "        for item in all_actions:\n",
        "            print(item)\n",
        "        print(\"================================\")\n",
        "\n",
        "        # Plot all actions\n",
        "        trade_plot = plot_trades_chart(df, all_actions)\n",
        "        return rewards_df, trade_plot\n",
        "    except Exception as e:\n",
        "        raise gr.Error(f\"An error occurred in the DQN module: {e}\")\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 8) Assemble Gradio UI with multiple tabs\n",
        "# --------------------------------------------------------------------------------\n",
        "chart_interface = gr.Interface(\n",
        "    fn=generate_plot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ticker\", value=\"SPY\"),\n",
        "        gr.Textbox(label=\"Start Date (YYYY-MM-DD)\", value=default_start_date),\n",
        "        gr.Textbox(label=\"End Date (YYYY-MM-DD)\",   value=default_end_date),\n",
        "        gr.Slider(minimum=3, maximum=20, step=1, value=8,  label=\"n_period\"),\n",
        "        gr.Slider(minimum=3, maximum=20, step=1, value=13, label=\"r_period\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(type=\"pil\",   label=\"Chart\"),\n",
        "        gr.Dataframe(label=\"Current Indicator Status\"),\n",
        "        gr.Dataframe(label=\"Historical Signals\")\n",
        "    ],\n",
        "    title=\"Oberon Trading Bot: Upper (ZLMA + RSI Trail + Momentum Labels + FOMC), Mid (Bressert, MCDX HBMA, MCDX Bars, Zero Lag MACD), IV\",\n",
        "    description=(\n",
        "        \"Panel 1: Price candlestick chart with overlaid EMAs, ZLMA, RSI Trail, momentum labels, and FOMC dates.\\n\"\n",
        "        \"Panel 2: Bressert indicator.\\n\"\n",
        "        \"Panel 3: MCDX indicator (HBMA & Signals).\\n\"\n",
        "        \"Panel 4: MCDX indicator (Bars: Dump, Down Candle, Pump Candle, Retest, Banker).\\n\"\n",
        "        \"Panel 5: Enhanced Zero Lag MACD (with cloud, histogram, and dots).\\n\"\n",
        "        \"Panel 6: VIX data.\\n\\n\"\n",
        "        \"Panel 7: Relative Momentum.\\n\\n\"\n",
        "        \"Above the chart is a table showing the current indicator status (including MACD and momentum metrics), and below the chart is a table of historical buy/sell signals (ordered from newest to oldest) with an additional Z-Score column.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Tab(\"Chart\"):\n",
        "        chart_interface.render()\n",
        "\n",
        "    with gr.Tab(\"Save Data\"):\n",
        "        gr.Markdown(\"### Save Historical Data & Signals to CSV\")\n",
        "        with gr.Row():\n",
        "            sd_ticker  = gr.Textbox(label=\"Ticker\", value=\"SPY\")\n",
        "            sd_start   = gr.Textbox(label=\"Start Date\", value=default_start_date)\n",
        "            sd_end     = gr.Textbox(label=\"End Date\",   value=default_end_date)\n",
        "        with gr.Row():\n",
        "            sd_n   = gr.Slider(minimum=3,  maximum=20, step=1, value=8,  label=\"n_period\")\n",
        "            sd_r   = gr.Slider(minimum=3,  maximum=20, step=1, value=13, label=\"r_period\")\n",
        "        with gr.Row():\n",
        "            data_csv_path    = gr.Textbox(label=\"Data CSV Filename\",    value=\"full_data.csv\")\n",
        "            signals_csv_path = gr.Textbox(label=\"Signals CSV Filename\", value=\"signals_data.csv\")\n",
        "        btn_save = gr.Button(\"Save to CSV\")\n",
        "        save_output_msg = gr.Markdown()\n",
        "\n",
        "        def save_data_wrapper(ticker, start, end, n, r, datafile, sigfile):\n",
        "            return save_historical_data(ticker, start, end, n, r, datafile, sigfile)\n",
        "\n",
        "        btn_save.click(\n",
        "            fn=save_data_wrapper,\n",
        "            inputs=[sd_ticker, sd_start, sd_end, sd_n, sd_r, data_csv_path, signals_csv_path],\n",
        "            outputs=save_output_msg\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"DQN Training\"):\n",
        "        gr.Markdown(\"### Train DQN from Saved CSV & Show Trades\")\n",
        "        csv_input = gr.Textbox(label=\"CSV file path\", value=\"full_data.csv\", info=\"Path to CSV created above.\")\n",
        "        episodes_input = gr.Slider(label=\"Episodes\", value=5, minimum=1, maximum=200, step=1)\n",
        "        run_dqn_btn = gr.Button(\"Train DQN & Show Trades\")\n",
        "        dqn_rewards_out = gr.Dataframe(label=\"Episode Rewards\")\n",
        "        dqn_tradeplot_out = gr.Image(type=\"pil\", label=\"DQN Trades Chart\")\n",
        "\n",
        "        run_dqn_btn.click(\n",
        "            fn=run_dqn_csv,\n",
        "            inputs=[csv_input, episodes_input],\n",
        "            outputs=[dqn_rewards_out, dqn_tradeplot_out]\n",
        "        )\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "4xEOCh0iRcKL",
        "outputId": "d9b2a158-5cb5-4f6c-abac-9e4d4426de62"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a5697eaf997e02daec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a5697eaf997e02daec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}