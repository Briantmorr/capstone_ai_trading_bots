{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio beautifulsoup4 yfinance torch"
      ],
      "metadata": {
        "id": "2aAxxALzQmBk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "wyUsFfiVRsqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOTE: DQN doesn't switch signals. (WIP)\n",
        "\n",
        "## Charting and data saving is fully functional"
      ],
      "metadata": {
        "id": "o67tmLWjO22Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.patches import Rectangle\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import io\n",
        "from PIL import Image\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# For the DQN portion:\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    import torch.nn.functional as F\n",
        "except ImportError:\n",
        "    print(\"PyTorch not installed. Please install it if you want to run the DQN training tab.\")\n",
        "\n",
        "# --- Debug flag ---\n",
        "DEBUG = True\n",
        "def debug_print(msg):\n",
        "    if DEBUG:\n",
        "        print(msg)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 1) Utility functions for scraping FOMC dates, downloading data, indicators\n",
        "# ------------------------------------------------------------------------\n",
        "def get_fomc_dates(start_date, end_date):\n",
        "    url = \"https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code != 200:\n",
        "            debug_print(f\"Error: Received status code {response.status_code}\")\n",
        "            return []\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        date_objs = []\n",
        "        for text in soup.stripped_strings:\n",
        "            matches = re.findall(r'([A-Za-z]+ \\d{1,2}, \\d{4})', text)\n",
        "            for date_str in matches:\n",
        "                try:\n",
        "                    dt = datetime.strptime(date_str, \"%B %d, %Y\")\n",
        "                    if dt not in date_objs:\n",
        "                        date_objs.append(dt)\n",
        "                except Exception:\n",
        "                    continue\n",
        "        date_objs = sorted(date_objs)\n",
        "        start_dt = pd.to_datetime(start_date)\n",
        "        end_dt = pd.to_datetime(end_date)\n",
        "        filtered_dates = [dt for dt in date_objs if start_dt <= dt <= end_dt]\n",
        "        return filtered_dates\n",
        "    except Exception as e:\n",
        "        debug_print(f\"Error scraping FOMC dates: {e}\")\n",
        "        return []\n",
        "\n",
        "def exp_average(series, period):\n",
        "    return series.ewm(span=period, adjust=False).mean()\n",
        "\n",
        "def wilder_average(series, length):\n",
        "    return series.ewm(alpha=1/length, adjust=False).mean()\n",
        "\n",
        "def weighted_moving_average(series, window):\n",
        "    weights = np.arange(1, window + 1)\n",
        "    return series.rolling(window).apply(lambda prices: np.dot(prices, weights) / weights.sum(), raw=True)\n",
        "\n",
        "def t3(source, length=21, vf=0.7):\n",
        "    ema1 = exp_average(source, length)\n",
        "    ema2 = exp_average(ema1, length)\n",
        "    gd1 = ema1 * (1 + vf) - ema2 * vf\n",
        "    ema11 = exp_average(gd1, length)\n",
        "    ema22 = exp_average(ema11, length)\n",
        "    gd2 = ema11 * (1 + vf) - ema22 * vf\n",
        "    ema111 = exp_average(gd2, length)\n",
        "    ema222 = exp_average(ema111, length)\n",
        "    gd3 = ema111 * (1 + vf) - ema222 * vf\n",
        "    return gd3\n",
        "\n",
        "def vwma(series, window, volume):\n",
        "    return (series * volume).rolling(window=window, min_periods=window).sum() / volume.rolling(window=window, min_periods=window).sum()\n",
        "\n",
        "def rsi_function(close, sensitivity, rsiPeriod, rsiBase):\n",
        "    delta = close.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=rsiPeriod, min_periods=rsiPeriod).mean()\n",
        "    avg_loss = loss.rolling(window=rsiPeriod, min_periods=rsiPeriod).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    rsi = rsi.fillna(50)\n",
        "    rsi_adj = sensitivity * (rsi - rsiBase)\n",
        "    return rsi_adj.clip(lower=0, upper=20)\n",
        "\n",
        "def download_data(ticker, start_date, end_date):\n",
        "    df = yf.download(ticker, start=pd.to_datetime(start_date), end=pd.to_datetime(end_date))\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [col[0].lower() for col in df.columns]\n",
        "    else:\n",
        "        df.columns = [str(col).lower() for col in df.columns]\n",
        "    return df\n",
        "\n",
        "def compute_bressert(df, n_period=8, r_period=13):\n",
        "    df['Ln'] = df['low'].rolling(window=n_period, min_periods=1).min()\n",
        "    df['Hn'] = df['high'].rolling(window=n_period, min_periods=1).max()\n",
        "    df['Y'] = ((df['close'] - df['Ln']) / (df['Hn'] - df['Ln'])) * 100\n",
        "    df['X'] = exp_average(df['Y'], r_period)\n",
        "    df['Lxn'] = df['X'].rolling(window=n_period, min_periods=1).min()\n",
        "    df['Hxn'] = df['X'].rolling(window=n_period, min_periods=1).max()\n",
        "    df['DSS'] = ((df['X'] - df['Lxn']) / (df['Hxn'] - df['Lxn'])) * 100\n",
        "    df['DSSb'] = exp_average(df['DSS'], r_period)\n",
        "    df['DSSsignal'] = df['DSSb'].shift(1)\n",
        "    return df\n",
        "\n",
        "def compute_zscore(df, length_m=14):\n",
        "    momentum = df['close'] - df['close'].shift(length_m)\n",
        "    avgMomentum = momentum.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=length_m, min_periods=length_m).std().fillna(0)\n",
        "    zScore = (momentum - avgMomentum) / stdDevMomentum\n",
        "    return zScore\n",
        "\n",
        "def compute_zero_lag_macd(source, fastLength=12, slowLength=26, signalLength=9, MacdEmaLength=9, useEma=True, useOldAlgo=False):\n",
        "    if useEma:\n",
        "        ma1 = source.ewm(span=fastLength, adjust=False).mean()\n",
        "        ma2 = ma1.ewm(span=fastLength, adjust=False).mean()\n",
        "    else:\n",
        "        ma1 = source.rolling(window=fastLength, min_periods=fastLength).mean()\n",
        "        ma2 = ma1.rolling(window=fastLength, min_periods=fastLength).mean()\n",
        "    zerolagEMA = (2 * ma1) - ma2\n",
        "    if useEma:\n",
        "        mas1 = source.ewm(span=slowLength, adjust=False).mean()\n",
        "        mas2 = mas1.ewm(span=slowLength, adjust=False).mean()\n",
        "    else:\n",
        "        mas1 = source.rolling(window=slowLength, min_periods=slowLength).mean()\n",
        "        mas2 = mas1.rolling(window=slowLength, min_periods=slowLength).mean()\n",
        "    zerolagslowMA = (2 * mas1) - mas2\n",
        "    ZeroLagMACD = zerolagEMA - zerolagslowMA\n",
        "    emasig1 = ZeroLagMACD.ewm(span=signalLength, adjust=False).mean()\n",
        "    emasig2 = emasig1.ewm(span=signalLength, adjust=False).mean()\n",
        "    if useOldAlgo:\n",
        "        signal = ZeroLagMACD.rolling(window=signalLength, min_periods=signalLength).mean()\n",
        "    else:\n",
        "        signal = (2 * emasig1) - emasig2\n",
        "    hist = ZeroLagMACD - signal\n",
        "    upHist = hist.copy()\n",
        "    upHist[hist <= 0] = 0\n",
        "    downHist = hist.copy()\n",
        "    downHist[hist > 0] = 0\n",
        "    EMALine = ZeroLagMACD.ewm(span=MacdEmaLength, adjust=False).mean()\n",
        "    dotUP = ZeroLagMACD.copy()\n",
        "    dotUP[(ZeroLagMACD.shift(1) >= signal.shift(1)) | (ZeroLagMACD < signal)] = np.nan\n",
        "    dotDN = ZeroLagMACD.copy()\n",
        "    dotDN[(ZeroLagMACD.shift(1) <= signal.shift(1)) | (ZeroLagMACD > signal)] = np.nan\n",
        "    return {\n",
        "        \"ZeroLagMACD\": ZeroLagMACD,\n",
        "        \"signal\": signal,\n",
        "        \"hist\": hist,\n",
        "        \"upHist\": upHist,\n",
        "        \"downHist\": downHist,\n",
        "        \"EMALine\": EMALine,\n",
        "        \"dotUP\": dotUP,\n",
        "        \"dotDN\": dotDN\n",
        "    }\n",
        "\n",
        "def extract_macd_signals(df, macd_dict, length_m=14):\n",
        "    macd_line = macd_dict[\"ZeroLagMACD\"]\n",
        "    macd_mean = macd_line.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    macd_std = macd_line.rolling(window=length_m, min_periods=length_m).std().replace(0, np.nan)\n",
        "    macd_zscore = (macd_line - macd_mean) / macd_std\n",
        "\n",
        "    signals = []\n",
        "    for i in range(1, len(df)):\n",
        "        if (pd.notna(macd_dict[\"ZeroLagMACD\"].iloc[i]) and\n",
        "            pd.notna(macd_dict[\"signal\"].iloc[i]) and\n",
        "            pd.notna(macd_dict[\"ZeroLagMACD\"].iloc[i-1]) and\n",
        "            pd.notna(macd_dict[\"signal\"].iloc[i-1])):\n",
        "            dt = df.index[i]\n",
        "            if macd_dict[\"ZeroLagMACD\"].iloc[i] > macd_dict[\"signal\"].iloc[i] and macd_dict[\"ZeroLagMACD\"].iloc[i-1] <= macd_dict[\"signal\"].iloc[i-1]:\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"ZeroLagMACD Buy\",\n",
        "                    \"Z-Score\": round(macd_zscore.iloc[i], 2) if not pd.isna(macd_zscore.iloc[i]) else None\n",
        "                })\n",
        "            elif macd_dict[\"ZeroLagMACD\"].iloc[i] < macd_dict[\"signal\"].iloc[i] and macd_dict[\"ZeroLagMACD\"].iloc[i-1] >= macd_dict[\"signal\"].iloc[i-1]:\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"ZeroLagMACD Sell\",\n",
        "                    \"Z-Score\": round(macd_zscore.iloc[i], 2) if not pd.isna(macd_zscore.iloc[i]) else None\n",
        "                })\n",
        "    signals_df = pd.DataFrame(signals)\n",
        "    if not signals_df.empty:\n",
        "        signals_df[\"Date\"] = pd.to_datetime(signals_df[\"Date\"])\n",
        "        signals_df = signals_df.sort_values(\"Date\", ascending=False)\n",
        "    return signals_df\n",
        "\n",
        "def extract_momentum_signals(df, length_m=14):\n",
        "    momentum = df['close'] - df['close'].shift(length_m)\n",
        "    avgMomentum = momentum.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=length_m, min_periods=length_m).std().fillna(0)\n",
        "    zScore = (momentum - avgMomentum) / stdDevMomentum\n",
        "\n",
        "    def grade(x):\n",
        "        if x >= 2:\n",
        "            return \"A\"\n",
        "        elif x >= 1:\n",
        "            return \"B\"\n",
        "        elif x >= 0:\n",
        "            return \"C\"\n",
        "        elif x >= -1:\n",
        "            return \"D\"\n",
        "        elif x >= -2:\n",
        "            return \"E\"\n",
        "        else:\n",
        "            return \"F\"\n",
        "\n",
        "    momentum_grade = zScore.apply(grade)\n",
        "    momentum_direction = momentum.apply(lambda x: \"Increasing\" if x > 0 else \"Decreasing\")\n",
        "\n",
        "    momentum_state = []\n",
        "    for i in range(len(momentum)):\n",
        "        if i == 0:\n",
        "            momentum_state.append(\"N/A\")\n",
        "        else:\n",
        "            if abs(momentum.iloc[i]) < abs(avgMomentum.iloc[i]) * 0.1:\n",
        "                momentum_state.append(\"Consolidating\")\n",
        "            elif momentum.iloc[i] * momentum.iloc[i-1] < 0:\n",
        "                momentum_state.append(\"Turning\")\n",
        "            elif momentum.iloc[i] > 0:\n",
        "                momentum_state.append(\"Positive Trending\")\n",
        "            else:\n",
        "                momentum_state.append(\"Negative Trending\")\n",
        "    momentum_state = pd.Series(momentum_state, index=df.index)\n",
        "\n",
        "    signals = []\n",
        "    for i in range(1, len(df)):\n",
        "        if momentum_grade.iloc[i] != momentum_grade.iloc[i-1]:\n",
        "            signals.append({\n",
        "                \"Date\": df.index[i].strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": f\"Momentum Grade Changed to {momentum_grade.iloc[i]}\",\n",
        "                \"Z-Score\": round(zScore.iloc[i], 2)\n",
        "            })\n",
        "        if momentum_direction.iloc[i] != momentum_direction.iloc[i-1]:\n",
        "            signals.append({\n",
        "                \"Date\": df.index[i].strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": f\"Momentum Direction Changed to {momentum_direction.iloc[i]}\",\n",
        "                \"Z-Score\": round(zScore.iloc[i], 2)\n",
        "            })\n",
        "        if momentum_state.iloc[i] != momentum_state.iloc[i-1]:\n",
        "            signals.append({\n",
        "                \"Date\": df.index[i].strftime(\"%Y-%m-%d\"),\n",
        "                \"Signal\": f\"Momentum State Changed to {momentum_state.iloc[i]}\",\n",
        "                \"Z-Score\": round(zScore.iloc[i], 2)\n",
        "            })\n",
        "    signals_df = pd.DataFrame(signals)\n",
        "    if not signals_df.empty:\n",
        "        signals_df[\"Date\"] = pd.to_datetime(signals_df[\"Date\"])\n",
        "        signals_df = signals_df.sort_values(\"Date\", ascending=False)\n",
        "    return signals_df\n",
        "\n",
        "def extract_signals(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX, length_m=14):\n",
        "    signals = []\n",
        "    zScore = compute_zscore(df, length_m)\n",
        "    # ZLMA signals\n",
        "    for dt in df.index[signalUp_ZLMA.fillna(False)]:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"ZLMA Buy\",\n",
        "            \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    for dt in df.index[signalDn_ZLMA.fillna(False)]:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"ZLMA Sell\",\n",
        "            \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    # Convert bullPt and bearPt to empty series if they are not pd.Series\n",
        "    if not isinstance(bullPt, pd.Series):\n",
        "        bullPt = pd.Series(dtype='float64')\n",
        "    if not isinstance(bearPt, pd.Series):\n",
        "        bearPt = pd.Series(dtype='float64')\n",
        "    # RSI signals\n",
        "    for dt in bullPt.dropna().index:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"RSI Buy\",\n",
        "            \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    for dt in bearPt.dropna().index:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"RSI Sell\",\n",
        "            \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    # Similarly, ensure upSig_MCDX and dnSig_MCDX are Series\n",
        "    if not isinstance(upSig_MCDX, pd.Series):\n",
        "        upSig_MCDX = pd.Series(dtype='float64')\n",
        "    if not isinstance(dnSig_MCDX, pd.Series):\n",
        "        dnSig_MCDX = pd.Series(dtype='float64')\n",
        "    # MCDX signals\n",
        "    for dt in upSig_MCDX.dropna().index:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"MCDX Buy\",\n",
        "            \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    for dt in dnSig_MCDX.dropna().index:\n",
        "        signals.append({\n",
        "            \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "            \"Signal\": \"MCDX Sell\",\n",
        "            \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "        })\n",
        "    # DSS crossover signals (assuming these columns are always in df)\n",
        "    for i in range(1, len(df)):\n",
        "        if (pd.notna(df['DSSb'].iloc[i]) and pd.notna(df['DSSsignal'].iloc[i]) and\n",
        "            pd.notna(df['DSSb'].iloc[i-1]) and pd.notna(df['DSSsignal'].iloc[i-1])):\n",
        "            if df['DSSb'].iloc[i] > df['DSSsignal'].iloc[i] and df['DSSb'].iloc[i-1] <= df['DSSsignal'].iloc[i-1]:\n",
        "                dt = df.index[i]\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"DSS Buy\",\n",
        "                    \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "                })\n",
        "            elif df['DSSb'].iloc[i] < df['DSSsignal'].iloc[i] and df['DSSb'].iloc[i-1] >= df['DSSsignal'].iloc[i-1]:\n",
        "                dt = df.index[i]\n",
        "                signals.append({\n",
        "                    \"Date\": dt.strftime(\"%Y-%m-%d\"),\n",
        "                    \"Signal\": \"DSS Sell\",\n",
        "                    \"Z-Score\": round(zScore.loc[dt], 2) if not pd.isna(zScore.loc[dt]) else None\n",
        "                })\n",
        "    signals_df = pd.DataFrame(signals)\n",
        "    if not signals_df.empty:\n",
        "        signals_df[\"Date\"] = pd.to_datetime(signals_df[\"Date\"])\n",
        "        signals_df = signals_df.sort_values(\"Date\", ascending=False)\n",
        "    return signals_df\n",
        "\n",
        "def extract_current_status(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX, length_m=14, macd_dict=None):\n",
        "    last = df.index[-1]\n",
        "    zlma_status = \"Buy\" if pd.notna(signalUp_ZLMA.loc[last]) and signalUp_ZLMA.loc[last] else \"Sell\"\n",
        "    rsi_status = \"Buy\" if pd.notna(bullPt.loc[last]) else \"Sell\"\n",
        "    mcdx_status = \"Buy\" if pd.notna(upSig_MCDX.loc[last]) else \"Sell\"\n",
        "    dss_status = \"Buy\" if df['DSSb'].iloc[-1] > df['DSSsignal'].iloc[-1] else \"Sell\"\n",
        "    zScore = compute_zscore(df, length_m)\n",
        "    current_zscore = round(zScore.iloc[-1], 2)\n",
        "    momentum = df['close'] - df['close'].shift(length_m)\n",
        "    avgMomentum = momentum.rolling(window=length_m, min_periods=length_m).mean()\n",
        "    stdDevMomentum = momentum.rolling(window=length_m, min_periods=length_m).std().fillna(0)\n",
        "    zScore_m = (momentum - avgMomentum) / stdDevMomentum\n",
        "    def get_momentum_grade(z):\n",
        "        if z >= 2:\n",
        "            return \"A\"\n",
        "        elif z >= 1:\n",
        "            return \"B\"\n",
        "        elif z >= 0:\n",
        "            return \"C\"\n",
        "        elif z >= -1:\n",
        "            return \"D\"\n",
        "        elif z >= -2:\n",
        "            return \"E\"\n",
        "        else:\n",
        "            return \"F\"\n",
        "    current_momentum_grade = get_momentum_grade(zScore_m.iloc[-1])\n",
        "    current_momentum_direction = \"Increasing\" if momentum.iloc[-1] > momentum.iloc[-2] else \"Decreasing\"\n",
        "    if len(df) < 2:\n",
        "        current_momentum_state = \"N/A\"\n",
        "    else:\n",
        "        if abs(momentum.iloc[-1]) < abs(avgMomentum.iloc[-1]) * 0.1:\n",
        "            current_momentum_state = \"Consolidating\"\n",
        "        elif momentum.iloc[-1] * momentum.iloc[-2] < 0:\n",
        "            current_momentum_state = \"Turning\"\n",
        "        elif momentum.iloc[-1] > 0:\n",
        "            current_momentum_state = \"Positive Trending\"\n",
        "        else:\n",
        "            current_momentum_state = \"Negative Trending\"\n",
        "    indicators = [\"ZLMA\", \"RSI\", \"MCDX\", \"DSS\", \"Z-Score\", \"Momentum Grade\", \"Momentum Direction\", \"Momentum State\"]\n",
        "    signals = [zlma_status, rsi_status, mcdx_status, dss_status, current_zscore, current_momentum_grade, current_momentum_direction, current_momentum_state]\n",
        "    if macd_dict is not None:\n",
        "        macd_status = \"Buy\" if macd_dict[\"ZeroLagMACD\"].iloc[-1] > macd_dict[\"signal\"].iloc[-1] else \"Sell\"\n",
        "        indicators.append(\"ZeroLagMACD\")\n",
        "        signals.append(macd_status)\n",
        "    return pd.DataFrame({\"Indicator\": indicators, \"Current Signal\": signals})\n",
        "\n",
        "def create_six_panel_combined_plot(df, ticker, start_date, end_date,\n",
        "                                   ema_value, zlma, signalUp_ZLMA, signalDn_ZLMA, zlma_color, ema_color,\n",
        "                                   rsi_ma_base, rsi_upper_bound, rsi_lower_bound, bullPt, bearPt,\n",
        "                                   b_X, b_DSSb, b_DSSsignal,\n",
        "                                   hbma, threshold, upSig_MCDX, dnSig_MCDX,\n",
        "                                   Dump, DnCandle, PumpCandle, Retest, Banker,\n",
        "                                   iv_series, macd_dict):\n",
        "    fig, axs = plt.subplots(6, 1, sharex=True, figsize=(12, 16),\n",
        "                            gridspec_kw={\"height_ratios\": [2, 1, 1, 1, 1, 1]})\n",
        "    fig.suptitle(f\"{ticker} - Combined Chart\", fontsize=14)\n",
        "    x_vals = mdates.date2num(df.index.to_pydatetime())\n",
        "\n",
        "    # Panel 1: Price + ZLMA + RSI Trail + FOMC markers\n",
        "    for i in range(len(df)):\n",
        "        o, c, h, l = df['open'].iloc[i], df['close'].iloc[i], df['high'].iloc[i], df['low'].iloc[i]\n",
        "        color = 'green' if c >= o else 'red'\n",
        "        axs[0].plot([x_vals[i], x_vals[i]], [l, h], color=color, linewidth=1, zorder=1)\n",
        "        candle_width = 0.6\n",
        "        axs[0].add_patch(Rectangle((x_vals[i] - candle_width/2, o), candle_width, c - o,\n",
        "                                   facecolor=color, edgecolor=color, zorder=2))\n",
        "    axs[0].plot(df.index, df['EMA_50'], label=\"EMA 50\", color='blue', linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, df['EMA_100'], label=\"EMA 100\", color='orange', linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, df['EMA_200'], label=\"EMA 200\", color='purple', linewidth=1.5, zorder=3)\n",
        "    axs[0].plot(df.index, df['EMA_500'], label=\"EMA 500\", color='brown', linewidth=1.5, zorder=3)\n",
        "\n",
        "    axs[0].plot(df.index, ema_value, label=\"EMA (Trend)\", color=ema_color, linewidth=2, zorder=4)\n",
        "    axs[0].plot(df.index, zlma,      label=\"ZLMA\",       color=zlma_color, linewidth=2, zorder=4)\n",
        "\n",
        "    axs[0].fill_between(df.index, zlma, ema_value, where=(zlma>=ema_value),\n",
        "                        facecolor=\"darkgreen\", alpha=0.3, interpolate=True, zorder=3)\n",
        "    axs[0].fill_between(df.index, zlma, ema_value, where=(zlma<ema_value),\n",
        "                        facecolor=\"darkred\", alpha=0.3, interpolate=True, zorder=3)\n",
        "\n",
        "    axs[0].scatter(df.index, zlma.where(signalUp_ZLMA), color=\"cyan\",    marker=\"o\", s=50, label=\"ZLMA Buy\",  zorder=5)\n",
        "    axs[0].scatter(df.index, zlma.where(signalDn_ZLMA), color=\"magenta\", marker=\"o\", s=50, label=\"ZLMA Sell\", zorder=5)\n",
        "\n",
        "    axs[0].plot(df.index, rsi_ma_base,        label=\"RSI Trail Base\",  color=\"gray\", linestyle=\"--\", linewidth=1)\n",
        "    axs[0].plot(df.index, rsi_upper_bound,    label=\"RSI Trail Upper\", color=\"blue\", linewidth=1)\n",
        "    axs[0].plot(df.index, rsi_lower_bound,    label=\"RSI Trail Lower\", color=\"red\",  linewidth=1)\n",
        "\n",
        "    axs[0].scatter(df.index, bullPt, color=\"cyan\",    marker=\"^\", s=50, label=\"RSI Buy\",  zorder=6)\n",
        "    axs[0].scatter(df.index, bearPt, color=\"magenta\", marker=\"v\", s=50, label=\"RSI Sell\", zorder=6)\n",
        "\n",
        "    axs[0].fill_between(df.index, rsi_ma_base,    rsi_upper_bound, facecolor=\"darkgreen\", alpha=0.2, interpolate=True)\n",
        "    axs[0].fill_between(df.index, rsi_lower_bound,rsi_ma_base,     facecolor=\"darkred\",   alpha=0.2, interpolate=True)\n",
        "\n",
        "    fomc_dates = get_fomc_dates(start_date, end_date)\n",
        "    for i, dt in enumerate(fomc_dates):\n",
        "        axs[0].axvline(dt, color=\"purple\", linestyle=\"--\", linewidth=1, label=\"FOMC\" if i==0 else \"\")\n",
        "\n",
        "    axs[0].set_ylabel(\"Price\")\n",
        "    axs[0].legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.15), ncol=5, fontsize=8)\n",
        "\n",
        "    # Panel 2: Bressert\n",
        "    axs[1].plot(df.index, b_X, label=\"X (EMA of Y)\", color=\"black\", linewidth=2)\n",
        "    marker_colors = ['black'] + [\n",
        "        'red' if b_X.iloc[i] < b_X.iloc[i-1] else 'green'\n",
        "        for i in range(1, len(b_X))\n",
        "    ]\n",
        "    axs[1].scatter(df.index, b_X, c=marker_colors, s=20, label=\"X Color\")\n",
        "    axs[1].plot(df.index, b_DSSb,       label=\"DSSb\",       color=\"blue\",    linewidth=2)\n",
        "    axs[1].plot(df.index, b_DSSsignal,  label=\"DSSsignal\",  color=\"magenta\", linewidth=2)\n",
        "    axs[1].axhline(50, color=\"gray\", linewidth=1)\n",
        "    axs[1].axhline(80, color=\"red\",  linewidth=2)\n",
        "    axs[1].axhline(20, color=\"green\",linewidth=2)\n",
        "    axs[1].set_ylabel(\"Bressert\")\n",
        "    axs[1].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 3: MCDX HBMA & Signals\n",
        "    axs[2].plot(df.index, hbma, label=\"HBMA\", color=\"black\", linewidth=2, zorder=3)\n",
        "    axs[2].axhline(threshold, color=\"gray\", linestyle=\"--\", label=\"Threshold\", zorder=2)\n",
        "    axs[2].scatter(df.index, upSig_MCDX, color=\"green\", marker=\"o\", s=50, label=\"MCDX Buy\",  zorder=4)\n",
        "    axs[2].scatter(df.index, dnSig_MCDX, color=\"red\",   marker=\"o\", s=50, label=\"MCDX Sell\", zorder=4)\n",
        "    axs[2].set_ylabel(\"MCDX HBMA\")\n",
        "    axs[2].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 4: MCDX Bars\n",
        "    axs[3].bar(df.index, Dump,       width=0.8, color=\"red\",      alpha=0.7, label=\"Dump\",        zorder=1)\n",
        "    axs[3].bar(df.index, DnCandle,   width=0.8, color=\"darkgray\", alpha=0.7, label=\"Down Candle\", zorder=1)\n",
        "    axs[3].bar(df.index, PumpCandle, width=0.8, color=\"green\",    alpha=0.7, label=\"Pump Candle\", zorder=1)\n",
        "    axs[3].bar(df.index, Retest,     width=0.8, color=\"darkred\",  alpha=0.7, label=\"Retest\",      zorder=1)\n",
        "    axs[3].bar(df.index, Banker,     width=0.8, color=\"#84AFC9\",  alpha=0.7, label=\"Banker\",      zorder=1)\n",
        "    axs[3].set_ylabel(\"MCDX Bars\")\n",
        "    axs[3].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 5: Enhanced Zero Lag MACD\n",
        "    axs[4].fill_between(df.index, macd_dict[\"ZeroLagMACD\"], macd_dict[\"signal\"],\n",
        "                        where=(macd_dict[\"ZeroLagMACD\"] >= macd_dict[\"signal\"]),\n",
        "                        facecolor=\"green\", alpha=0.3, interpolate=True)\n",
        "    axs[4].fill_between(df.index, macd_dict[\"ZeroLagMACD\"], macd_dict[\"signal\"],\n",
        "                        where=(macd_dict[\"ZeroLagMACD\"] < macd_dict[\"signal\"]),\n",
        "                        facecolor=\"red\", alpha=0.3, interpolate=True)\n",
        "    axs[4].plot(df.index, macd_dict[\"ZeroLagMACD\"], label=\"ZeroLagMACD\", color=\"green\", linewidth=1)\n",
        "    axs[4].plot(df.index, macd_dict[\"signal\"],      label=\"Signal\",      color=\"red\",   linewidth=1)\n",
        "    axs[4].bar(df.index, macd_dict[\"upHist\"]   *2,  label=\"Histogram Up\",   color=\"gray\", width=0.8)\n",
        "    axs[4].bar(df.index, macd_dict[\"downHist\"] *2,  label=\"Histogram Down\", color=\"red\",  width=0.8)\n",
        "    axs[4].scatter(df.index, macd_dict[\"dotUP\"], color=\"green\",  marker=\"o\", s=50, label=\"Dot Up\")\n",
        "    axs[4].scatter(df.index, macd_dict[\"dotDN\"], color=\"red\",    marker=\"o\", s=50, label=\"Dot Down\")\n",
        "    axs[4].set_ylabel(\"ZeroLag MACD\")\n",
        "    axs[4].legend(loc=\"lower left\", fontsize=8)\n",
        "\n",
        "    # Panel 6: Implied Volatility\n",
        "    axs[5].plot(df.index, iv_series, label=\"Implied Volatility (VIX)\", color=\"darkorange\", linewidth=2)\n",
        "    axs[5].set_ylabel(\"IV\")\n",
        "    axs[5].legend(loc=\"lower left\", fontsize=8)\n",
        "    axs[5].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
        "    for tick in axs[5].get_xticklabels():\n",
        "        tick.set_rotation(45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def figure_to_pil(fig):\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 2) The main chart-generation function (used by Chart tab)\n",
        "# ------------------------------------------------------------------------\n",
        "default_end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "default_start_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def generate_plot(ticker=\"SPY\", start_date=default_start_date, end_date=default_end_date, n_period=8, r_period=13):\n",
        "    try:\n",
        "        df = download_data(ticker, start_date, end_date)\n",
        "        if df.empty:\n",
        "            raise gr.Error(f\"No data for {ticker} from {start_date} to {end_date}\")\n",
        "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
        "            if col not in df.columns:\n",
        "                raise gr.Error(f\"Missing {col} data for {ticker}\")\n",
        "\n",
        "        df['EMA_50']  = exp_average(df['close'], 50)\n",
        "        df['EMA_100'] = exp_average(df['close'], 100)\n",
        "        df['EMA_200'] = exp_average(df['close'], 200)\n",
        "        df['EMA_500'] = exp_average(df['close'], 500)\n",
        "\n",
        "        movAvgLength = 15\n",
        "        ema_value  = exp_average(df['close'], movAvgLength)\n",
        "        correction = df['close'] + (df['close'] - ema_value)\n",
        "        zlma       = exp_average(correction, movAvgLength)\n",
        "        signalUp_ZLMA = (zlma > ema_value) & (zlma.shift(1) <= ema_value.shift(1))\n",
        "        signalDn_ZLMA = (zlma < ema_value) & (zlma.shift(1) >= ema_value.shift(1))\n",
        "        zlma_color = \"green\" if zlma.iloc[-1] > zlma.iloc[-2] else \"red\"\n",
        "        ema_color  = \"green\" if ema_value.iloc[-1] < zlma.iloc[-1] else \"red\"\n",
        "\n",
        "        df = compute_bressert(df, n_period, r_period)\n",
        "        b_X         = df['X']\n",
        "        b_DSSb      = df['DSSb']\n",
        "        b_DSSsignal = df['DSSsignal']\n",
        "\n",
        "        RSIBaseBanker    = 50;   RSIPeriodBanker    = 50\n",
        "        RSIBaseHotMoney  = 30;   RSIPeriodHotMoney  = 40\n",
        "        SensitivityBanker= 1.5;  SensitivityHotMoney= 0.7\n",
        "        threshold        = 8.5\n",
        "\n",
        "        rsi_Banker  = rsi_function(df['close'], SensitivityBanker, RSIPeriodBanker, RSIBaseBanker)\n",
        "        rsi_HotMoney= rsi_function(df['close'], SensitivityHotMoney, RSIPeriodHotMoney, RSIBaseHotMoney)\n",
        "\n",
        "        hot  = rsi_HotMoney\n",
        "        bank = rsi_Banker\n",
        "\n",
        "        hotma2  = wilder_average(hot, 2)\n",
        "        hotma7  = wilder_average(hot, 7)\n",
        "        hotma31 = wilder_average(hot,31)\n",
        "        hotma   = exp_average((hotma2*34 + hotma7*33 + hotma31*33)/100, 2)\n",
        "\n",
        "        bankma2  = df['close'].rolling(window=2, min_periods=2).mean()\n",
        "        bankma7  = exp_average(bank, 7)\n",
        "        bankma31 = exp_average(bank,31)\n",
        "        bankma   = ((bankma2*70 + bankma7*20 + bankma31*10)/100).rolling(window=2, min_periods=2).mean()\n",
        "        banksignal = wilder_average(bankma, 4)\n",
        "\n",
        "        hbAvg = ((hot*10) + (hotma*35) + (wilder_average(hotma,2)*15) + (bankma*35) + (banksignal*5)) / 100\n",
        "        hbma = vwma(hbAvg, 2, df['volume'])\n",
        "\n",
        "        downtrendsignal = (hotma.shift(1) >= wilder_average(hotma,2).shift(1)) & (hotma < wilder_average(hotma,2))\n",
        "        uptrendsignal   = (hotma.shift(1) <= wilder_average(hotma,2).shift(1)) & (hotma > wilder_average(hotma,2))\n",
        "\n",
        "        upSig_MCDX = hbma.where(uptrendsignal,   np.nan)\n",
        "        dnSig_MCDX = hbma.where(downtrendsignal, np.nan)\n",
        "\n",
        "        Dump = bank.where(bank < bank.shift(1) / 1.75, np.nan)\n",
        "        dnCond = (bank < bank.shift(1)) & (bank < bank.shift(2)) & (bank.shift(1) < bank.shift(2)) & \\\n",
        "                 (bank < bank.shift(3)) & (bank < bank.shift(4)) & (bank.shift(3) < bank.shift(4)) & \\\n",
        "                 (bank.shift(6) > 8.5) & (bank < 10)\n",
        "        DnCandle   = bank.where(dnCond, np.nan)\n",
        "        PumpCandle = bank.where(bank > hbma, np.nan)\n",
        "        Retest     = bank.where((banksignal > bankma) & (bank > 0), np.nan)\n",
        "        Banker     = bank\n",
        "\n",
        "        lookbackPeriod = 15\n",
        "        atrLength = 27\n",
        "        atrMultiplier = 0.1\n",
        "        rsiLowerThreshold = 40\n",
        "        rsiUpperThreshold = 60\n",
        "\n",
        "        ohlc4 = (df['open'] + df['high'] + df['low'] + df['close'])/4\n",
        "        rsi_ma_base = t3(ohlc4, length=lookbackPeriod, vf=0.7)\n",
        "        tr_series = pd.concat([df['high']-df['low'],\n",
        "                               abs(df['high']-df['close'].shift(1)),\n",
        "                               abs(df['low']-df['close'].shift(1))], axis=1).max(axis=1)\n",
        "        nzTR = tr_series.fillna(df['high']-df['low'])\n",
        "        f_volatility = wilder_average(nzTR, atrLength) * atrMultiplier\n",
        "        rsi_upper_bound = rsi_ma_base + (rsiUpperThreshold - 50)/10 * f_volatility\n",
        "        rsi_lower_bound = rsi_ma_base - (50 - rsiLowerThreshold)/10 * f_volatility\n",
        "\n",
        "        crossUp = (ohlc4 > rsi_upper_bound) & (ohlc4.shift(1) <= rsi_upper_bound.shift(1))\n",
        "        crossDn=  (df['close'] < rsi_lower_bound) & (df['close'].shift(1) >= rsi_lower_bound.shift(1))\n",
        "        bullPt = rsi_lower_bound.where(crossUp, np.nan)\n",
        "        bearPt = rsi_upper_bound.where(crossDn, np.nan)\n",
        "\n",
        "        vix_df = yf.download(\"^VIX\", start=pd.to_datetime(start_date), end=pd.to_datetime(end_date))\n",
        "        if vix_df.empty:\n",
        "            iv_series = pd.Series(np.nan, index=df.index)\n",
        "        else:\n",
        "            vix_df.index = pd.to_datetime(vix_df.index)\n",
        "            iv_series = vix_df[\"Close\"].reindex(df.index, method=\"ffill\")\n",
        "\n",
        "        fomc_dates = get_fomc_dates(start_date, end_date)\n",
        "\n",
        "        macd_dict = compute_zero_lag_macd(df['close'], fastLength=12, slowLength=26, signalLength=9,\n",
        "                                          MacdEmaLength=9, useEma=True, useOldAlgo=False)\n",
        "\n",
        "        fig = create_six_panel_combined_plot(\n",
        "            df, ticker, start_date, end_date,\n",
        "            ema_value, zlma, signalUp_ZLMA, signalDn_ZLMA, zlma_color, ema_color,\n",
        "            rsi_ma_base, rsi_upper_bound, rsi_lower_bound, bullPt, bearPt,\n",
        "            b_X, b_DSSb, b_DSSsignal,\n",
        "            hbma, threshold, upSig_MCDX, dnSig_MCDX,\n",
        "            Dump, DnCandle, PumpCandle, Retest, Banker,\n",
        "            iv_series, macd_dict\n",
        "        )\n",
        "\n",
        "        ax0 = fig.axes[0]\n",
        "        for i, dt in enumerate(fomc_dates):\n",
        "            ax0.axvline(dt, color=\"purple\", linestyle=\"--\", linewidth=1, label=\"FOMC\" if i==0 else \"\")\n",
        "        handles, labels = ax0.get_legend_handles_labels()\n",
        "        unique = dict(zip(labels, handles))\n",
        "        ax0.legend(unique.values(), unique.keys(), loc=\"lower right\", ncol=3, fontsize=8)\n",
        "\n",
        "        signals_df         = extract_signals(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX, length_m=14)\n",
        "        momentum_signals_df= extract_momentum_signals(df, length_m=14)\n",
        "        macd_signals_df    = extract_macd_signals(df, macd_dict, length_m=14)\n",
        "\n",
        "        historical_signals_df = pd.concat([signals_df, momentum_signals_df, macd_signals_df], ignore_index=True)\n",
        "        if not historical_signals_df.empty:\n",
        "            historical_signals_df[\"Date\"] = pd.to_datetime(historical_signals_df[\"Date\"])\n",
        "            historical_signals_df = historical_signals_df.sort_values(\"Date\", ascending=False)\n",
        "\n",
        "        current_status_df = extract_current_status(\n",
        "            df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt, upSig_MCDX, dnSig_MCDX,\n",
        "            length_m=14, macd_dict=macd_dict\n",
        "        )\n",
        "\n",
        "        pil_img = figure_to_pil(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "        return pil_img, current_status_df, historical_signals_df\n",
        "\n",
        "    except Exception as e:\n",
        "        debug_print(f\"Error: {e}\")\n",
        "        raise gr.Error(f\"An error occurred: {e}\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 3) New function to save data + signals to CSV\n",
        "# ------------------------------------------------------------------------\n",
        "def save_historical_data(ticker=\"SPY\", start_date=default_start_date, end_date=default_end_date,\n",
        "                         n_period=8, r_period=13,\n",
        "                         data_filename=\"full_data.csv\", signals_filename=\"signals_data.csv\"):\n",
        "    try:\n",
        "        df = download_data(ticker, start_date, end_date)\n",
        "        if df.empty:\n",
        "            raise gr.Error(f\"No data for {ticker} from {start_date} to {end_date}\")\n",
        "        for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
        "            if col not in df.columns:\n",
        "                raise gr.Error(f\"Missing {col} data for {ticker}\")\n",
        "\n",
        "        df['EMA_50']  = exp_average(df['close'], 50)\n",
        "        df['EMA_100'] = exp_average(df['close'], 100)\n",
        "        df['EMA_200'] = exp_average(df['close'], 200)\n",
        "        df['EMA_500'] = exp_average(df['close'], 500)\n",
        "\n",
        "        movAvgLength = 15\n",
        "        ema_value  = exp_average(df['close'], movAvgLength)\n",
        "        correction = df['close'] + (df['close'] - ema_value)\n",
        "        zlma       = exp_average(correction, movAvgLength)\n",
        "        signalUp_ZLMA = (zlma > ema_value) & (zlma.shift(1) <= ema_value.shift(1))\n",
        "        signalDn_ZLMA = (zlma < ema_value) & (zlma.shift(1) >= ema_value.shift(1))\n",
        "\n",
        "        df = compute_bressert(df, n_period, r_period)\n",
        "\n",
        "        RSIBaseBanker     = 50;   RSIPeriodBanker    = 50\n",
        "        RSIBaseHotMoney   = 30;   RSIPeriodHotMoney  = 40\n",
        "        SensitivityBanker = 1.5;  SensitivityHotMoney= 0.7\n",
        "        threshold         = 8.5\n",
        "\n",
        "        rsi_Banker   = rsi_function(df['close'], SensitivityBanker, RSIPeriodBanker, RSIBaseBanker)\n",
        "        rsi_HotMoney = rsi_function(df['close'], SensitivityHotMoney, RSIPeriodHotMoney, RSIBaseHotMoney)\n",
        "        hot  = rsi_HotMoney\n",
        "        bank = rsi_Banker\n",
        "\n",
        "        hotma2  = wilder_average(hot, 2)\n",
        "        hotma7  = wilder_average(hot, 7)\n",
        "        hotma31 = wilder_average(hot, 31)\n",
        "        hotma   = exp_average((hotma2*34 + hotma7*33 + hotma31*33)/100, 2)\n",
        "\n",
        "        bankma2  = df['close'].rolling(window=2, min_periods=2).mean()\n",
        "        bankma7  = exp_average(bank, 7)\n",
        "        bankma31 = exp_average(bank, 31)\n",
        "        bankma   = ((bankma2*70 + bankma7*20 + bankma31*10)/100).rolling(window=2, min_periods=2).mean()\n",
        "        banksignal = wilder_average(bankma, 4)\n",
        "\n",
        "        hbAvg = ((hot*10) + (hotma*35) + (wilder_average(hotma,2)*15) + (bankma*35) + (banksignal*5)) / 100\n",
        "        hbma = vwma(hbAvg, 2, df['volume'])\n",
        "\n",
        "        downtrendsignal = (hotma.shift(1) >= wilder_average(hotma,2).shift(1)) & (hotma < wilder_average(hotma,2))\n",
        "        uptrendsignal   = (hotma.shift(1) <= wilder_average(hotma,2).shift(1)) & (hotma > wilder_average(hotma,2))\n",
        "        upSig_MCDX = hbma.where(uptrendsignal, np.nan)\n",
        "        dnSig_MCDX = hbma.where(downtrendsignal, np.nan)\n",
        "\n",
        "        df['ZLMA'] = zlma\n",
        "        df['HBMA'] = hbma\n",
        "        df['RSI_Banker'] = bank\n",
        "        df['RSI_HotMoney'] = hot\n",
        "\n",
        "        Dump = bank.where(bank < bank.shift(1) / 1.75, np.nan)\n",
        "        dnCond = (bank < bank.shift(1)) & (bank < bank.shift(2)) & (bank.shift(1) < bank.shift(2)) & \\\n",
        "                 (bank < bank.shift(3)) & (bank < bank.shift(4)) & (bank.shift(3) < bank.shift(4)) & \\\n",
        "                 (bank.shift(6) > 8.5) & (bank < 10)\n",
        "        DnCandle   = bank.where(dnCond, np.nan)\n",
        "        PumpCandle = bank.where(bank > hbma, np.nan)\n",
        "        Retest     = bank.where((banksignal > bankma) & (bank > 0), np.nan)\n",
        "\n",
        "        lookbackPeriod = 15\n",
        "        atrLength = 27\n",
        "        atrMultiplier = 0.1\n",
        "        rsiLowerThreshold = 40\n",
        "        rsiUpperThreshold = 60\n",
        "\n",
        "        ohlc4 = (df['open'] + df['high'] + df['low'] + df['close'])/4\n",
        "        rsi_ma_base = t3(ohlc4, length=lookbackPeriod, vf=0.7)\n",
        "        tr_series = pd.concat([df['high']-df['low'],\n",
        "                               abs(df['high']-df['close'].shift(1)),\n",
        "                               abs(df['low']-df['close'].shift(1))], axis=1).max(axis=1)\n",
        "        nzTR = tr_series.fillna(df['high']-df['low'])\n",
        "        f_volatility = wilder_average(nzTR, atrLength) * atrMultiplier\n",
        "        rsi_upper_bound = rsi_ma_base + (rsiUpperThreshold - 50)/10 * f_volatility\n",
        "        rsi_lower_bound = rsi_ma_base - (50 - rsiLowerThreshold)/10 * f_volatility\n",
        "\n",
        "        crossUp = (ohlc4 > rsi_upper_bound) & (ohlc4.shift(1) <= rsi_upper_bound.shift(1))\n",
        "        crossDn = (df['close'] < rsi_lower_bound) & (df['close'].shift(1) >= rsi_lower_bound.shift(1))\n",
        "        bullPt = rsi_lower_bound.where(crossUp, np.nan)\n",
        "        bearPt = rsi_upper_bound.where(crossDn, np.nan)\n",
        "\n",
        "        macd_dict = compute_zero_lag_macd(df['close'], fastLength=12, slowLength=26, signalLength=9,\n",
        "                                          MacdEmaLength=9, useEma=True, useOldAlgo=False)\n",
        "\n",
        "        signals_df = extract_signals(df, signalUp_ZLMA, signalDn_ZLMA, bullPt, bearPt,\n",
        "                                      upSig_MCDX, dnSig_MCDX, length_m=14)\n",
        "        momentum_signals_df = extract_momentum_signals(df, length_m=14)\n",
        "        macd_signals_df = extract_macd_signals(df, macd_dict, length_m=14)\n",
        "        historical_signals_df = pd.concat([signals_df, momentum_signals_df, macd_signals_df], ignore_index=True)\n",
        "        if not historical_signals_df.empty:\n",
        "            historical_signals_df[\"Date\"] = pd.to_datetime(historical_signals_df[\"Date\"])\n",
        "            historical_signals_df = historical_signals_df.sort_values(\"Date\", ascending=False)\n",
        "\n",
        "        # *** NEW PART: Create per-indicator 0/1 columns ***\n",
        "        indicator_list = [\"ZLMA\", \"RSI\", \"MCDX\", \"DSS\", \"ZeroLagMACD\"]\n",
        "        signals_grouped = historical_signals_df.groupby('Date')['Signal'].apply(list)\n",
        "        for ind in indicator_list:\n",
        "            df[ind + \"_Buy\"] = df.index.to_series().apply(\n",
        "                lambda d: 1 if any((ind in s and \"Buy\" in s) for s in signals_grouped.get(d, [])) else 0\n",
        "            )\n",
        "            df[ind + \"_Sell\"] = df.index.to_series().apply(\n",
        "                lambda d: 1 if any((ind in s and \"Sell\" in s) for s in signals_grouped.get(d, [])) else 0\n",
        "            )\n",
        "        # *** End of new part ***\n",
        "\n",
        "        df.to_csv(data_filename)\n",
        "        historical_signals_df.to_csv(signals_filename, index=False)\n",
        "        return f\"Saved {data_filename} and {signals_filename} successfully.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        debug_print(f\"Error: {e}\")\n",
        "        raise gr.Error(f\"An error occurred: {e}\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 4) DQN + environment that reads from CSV\n",
        "# ------------------------------------------------------------------------\n",
        "class TradingEnv:\n",
        "    \"\"\"\n",
        "    An environment that:\n",
        "      1) Randomly picks a start day within the dataset for each episode.\n",
        "      2) Randomly picks an initial position (long, short, or flat).\n",
        "      3) Gives a large alignment bonus with signals and a penalty for ignoring them.\n",
        "      4) Charges a transaction cost for flipping positions.\n",
        "      5) Limits how long you can hold the same position to 'max_hold_days' to force re-entry.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, window_size=3, max_hold_days=10):\n",
        "        \"\"\"\n",
        "        df must include columns:\n",
        "          'close' + [ZLMA_Buy, ZLMA_Sell, RSI_Buy, RSI_Sell, MCDX_Buy, MCDX_Sell, DSS_Buy, DSS_Sell, ZeroLagMACD_Buy, ZeroLagMACD_Sell]\n",
        "        \"\"\"\n",
        "        self.df_original = df.reset_index(drop=False).copy()  # keep 'Date' as a column if needed\n",
        "        self.length_full = len(self.df_original)\n",
        "        self.window_size = window_size\n",
        "        self.max_hold_days = max_hold_days\n",
        "\n",
        "        # The columns containing your signals\n",
        "        self.signal_cols = [\n",
        "            \"ZLMA_Buy\", \"ZLMA_Sell\", \"RSI_Buy\", \"RSI_Sell\",\n",
        "            \"MCDX_Buy\", \"MCDX_Sell\", \"DSS_Buy\", \"DSS_Sell\",\n",
        "            \"ZeroLagMACD_Buy\", \"ZeroLagMACD_Sell\"\n",
        "        ]\n",
        "        for col in self.signal_cols:\n",
        "            if col not in self.df_original.columns:\n",
        "                self.df_original[col] = 0\n",
        "\n",
        "        self.random_start_index = 0\n",
        "        self.current_step = 0\n",
        "        self.position = 0   # +1=long, -1=short, 0=flat\n",
        "        self.hold_counter = 0\n",
        "        self.history_buffer = []\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Each episode, we:\n",
        "          1) Pick a random start day in the dataset (leaving enough days to step through).\n",
        "          2) Possibly pick a random initial position.\n",
        "          3) Build self.df as a subset from start_index => end.\n",
        "        \"\"\"\n",
        "        # pick a random start day, say anywhere up to length_full - 10 so we have at least some days\n",
        "        self.random_start_index = random.randint(0, self.length_full - self.window_size - 2)\n",
        "        self.df = self.df_original.iloc[self.random_start_index:].reset_index(drop=True).copy()\n",
        "        self.length = len(self.df)\n",
        "\n",
        "        # random initial position: pick from {0=flat, +1=long, -1=short}\n",
        "        self.position = random.choice([0, 1, -1])\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.hold_counter = 1 if self.position != 0 else 0\n",
        "        self.history_buffer = []\n",
        "        for _ in range(self.window_size):\n",
        "            self._append_history()\n",
        "        return self._get_state()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        action: 0=Hold, 1=Go Long, 2=Go Short\n",
        "        We'll do:\n",
        "          - daily PnL\n",
        "          - large alignment bonus if signals match position\n",
        "          - penalty if signals are ignored\n",
        "          - forced close if hold_counter > max_hold_days\n",
        "          - transaction cost if flipping\n",
        "        \"\"\"\n",
        "        prev_position = self.position\n",
        "        current_price = self.df.loc[self.current_step, 'close']\n",
        "        reward = 0.0\n",
        "\n",
        "        # Basic daily PnL\n",
        "        if self.current_step > 0:\n",
        "            price_prev = self.df.loc[self.current_step - 1, 'close']\n",
        "            reward = (current_price - price_prev) * prev_position\n",
        "\n",
        "        # Update position if action changed it\n",
        "        new_position = 0\n",
        "        if action == 1:\n",
        "            new_position = 1\n",
        "        elif action == 2:\n",
        "            new_position = -1\n",
        "        # else remain 0 => hold\n",
        "\n",
        "        # Transaction cost if flipping from +1 to -1 or vice versa\n",
        "        if (prev_position ==  1 and new_position == -1) or (prev_position == -1 and new_position == 1):\n",
        "            reward -= 0.001 * current_price  # transaction cost\n",
        "\n",
        "        # If new_position != prev_position, we are switching\n",
        "        # If new_position=0, that means we closed the position\n",
        "        if new_position != prev_position:\n",
        "            self.position = new_position\n",
        "            self.hold_counter = 1 if self.position != 0 else 0\n",
        "        else:\n",
        "            # holding the same position\n",
        "            if self.position != 0:\n",
        "                self.hold_counter += 1\n",
        "\n",
        "        # If hold_counter goes beyond max_hold_days, forcibly close\n",
        "        if self.hold_counter > self.max_hold_days:\n",
        "            # forcibly close\n",
        "            # This means position -> 0\n",
        "            # Possibly penalize ignoring?\n",
        "            reward -= 0.02 * current_price\n",
        "            self.position = 0\n",
        "            self.hold_counter = 0\n",
        "\n",
        "        # Signals alignment\n",
        "        day_signals = self.df.loc[self.current_step, self.signal_cols].values\n",
        "        buy_sum = day_signals[0::2].sum()   # sum of the buy columns\n",
        "        sell_sum = day_signals[1::2].sum()  # sum of the sell columns\n",
        "\n",
        "        # Big alignment bonus, plus ignoring penalty\n",
        "        # e.g. bigger bonus = 0.05 * sum, penalty = 0.02\n",
        "        if self.position == 1:\n",
        "            # If aligned with buy signals\n",
        "            reward += 0.05 * buy_sum\n",
        "            # If ignoring sell signals\n",
        "            reward -= 0.02 * sell_sum\n",
        "        elif self.position == -1:\n",
        "            # If aligned with sell signals\n",
        "            reward += 0.05 * sell_sum\n",
        "            # If ignoring buy signals\n",
        "            reward -= 0.02 * buy_sum\n",
        "        else:\n",
        "            # flat => we might penalize ignoring both\n",
        "            if buy_sum > 0 or sell_sum > 0:\n",
        "                reward -= 0.01 * (buy_sum + sell_sum)\n",
        "\n",
        "        # Move forward\n",
        "        self.current_step += 1\n",
        "        done = (self.current_step >= self.length - 1)  # stop near the end\n",
        "\n",
        "        self._append_history()\n",
        "        state = self._get_state()\n",
        "        return state, reward, done\n",
        "\n",
        "    def _append_history(self):\n",
        "        if self.current_step < self.length:\n",
        "            row = self.df.loc[self.current_step, [\"close\"] + self.signal_cols].values\n",
        "        else:\n",
        "            row = self.df.loc[self.length - 1, [\"close\"] + self.signal_cols].values\n",
        "        self.history_buffer.append(row.astype(np.float32))\n",
        "        if len(self.history_buffer) > self.window_size:\n",
        "            self.history_buffer.pop(0)\n",
        "\n",
        "    def _get_state(self):\n",
        "        # shape: (window_size, 1+10) => flatten => plus position\n",
        "        history_array = np.array(self.history_buffer)\n",
        "        flattened = history_array.flatten()\n",
        "        return np.concatenate([flattened, [float(self.position)]], dtype=np.float32)\n",
        "\n",
        "# For window_size=3, state dimension = 3*11 + 1 = 33 + 1 = 34.\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=34, hidden_dim=64, output_dim=3):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def train_dqn_from_df(df, episodes=50, gamma=0.99, lr=1e-3,\n",
        "                      epsilon=1.0, epsilon_decay=0.99, epsilon_min=0.01):\n",
        "    env = TradingEnv(df, window_size=3, max_hold_days=10)\n",
        "    policy_net = QNetwork(input_dim=34, hidden_dim=64, output_dim=3)\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "    rewards_per_episode = []\n",
        "    for ep in range(episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0.0\n",
        "        while not done:\n",
        "            # Epsilon-greedy\n",
        "            if np.random.rand() < epsilon:\n",
        "                action = np.random.randint(0, 3)\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    s = torch.FloatTensor(state).unsqueeze(0)\n",
        "                    q_values = policy_net(s)\n",
        "                    action = q_values.argmax(dim=1).item()\n",
        "\n",
        "            next_state, reward, done = env.step(action)\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Compute target for Q-learning\n",
        "            with torch.no_grad():\n",
        "                s_next = torch.FloatTensor(next_state).unsqueeze(0)\n",
        "                next_q_values = policy_net(s_next)\n",
        "                max_next = next_q_values.max(dim=1)[0].item()\n",
        "                target_value = reward + (0 if done else gamma * max_next)\n",
        "\n",
        "            # Q-learning update\n",
        "            s = torch.FloatTensor(state).unsqueeze(0)\n",
        "            q_values = policy_net(s)\n",
        "            q_current = q_values[0, action]\n",
        "            loss = F.mse_loss(q_current, torch.FloatTensor([target_value]))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "        rewards_per_episode.append({\"Episode\": ep+1, \"Total Reward\": episode_reward})\n",
        "\n",
        "    return pd.DataFrame(rewards_per_episode), policy_net\n",
        "\n",
        "def simulate_dqn_trades(policy_net, df):\n",
        "    \"\"\"\n",
        "    Runs a simulation with the trained policy (greedy) and logs an action every day\n",
        "    (Buy, Sell, or Hold), along with the date and price.\n",
        "    \"\"\"\n",
        "    env = TradingEnv(df)\n",
        "    state = env.reset()\n",
        "    all_actions = []  # We'll store (date, action_name, price) for every day\n",
        "    day_idx = 0\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            s = torch.FloatTensor(state).unsqueeze(0)\n",
        "            q_values = policy_net(s)\n",
        "            action = q_values.argmax(dim=1).item()\n",
        "\n",
        "        # Convert numeric action => text label\n",
        "        if action == 1:\n",
        "            action_name = \"Buy\"\n",
        "        elif action == 2:\n",
        "            action_name = \"Sell\"\n",
        "        else:\n",
        "            action_name = \"Hold\"\n",
        "\n",
        "        if day_idx < len(df):\n",
        "            date_here = df.index[day_idx]\n",
        "            price_here = df.loc[date_here, 'close']\n",
        "            all_actions.append((date_here, action_name, price_here))\n",
        "\n",
        "        next_state, reward, done = env.step(action)\n",
        "        state = next_state\n",
        "        day_idx += 1\n",
        "\n",
        "    return all_actions\n",
        "\n",
        "def plot_trades_chart(df, all_actions):\n",
        "    \"\"\"\n",
        "    Plots a marker for every daily action:\n",
        "      - Green ^ for Buy\n",
        "      - Red v for Sell\n",
        "      - Blue . for Hold\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(df.index, df['close'], label=\"Close Price\")\n",
        "\n",
        "    # We track which legend labels have been used so we don't repeat them\n",
        "    used_labels = set()\n",
        "\n",
        "    for (date, action_name, price) in all_actions:\n",
        "        if action_name == \"Buy\":\n",
        "            marker, color = \"^\", \"green\"\n",
        "        elif action_name == \"Sell\":\n",
        "            marker, color = \"v\", \"red\"\n",
        "        else:  # Hold\n",
        "            marker, color = \".\", \"blue\"\n",
        "\n",
        "        # Only add a legend entry once per action_name\n",
        "        lbl = action_name if action_name not in used_labels else None\n",
        "        used_labels.add(action_name)\n",
        "\n",
        "        ax.scatter(date, price, marker=marker, color=color, s=100, label=lbl)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_title(\"DQN Trades on Price Chart (All Actions Plotted)\")\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "    buf.seek(0)\n",
        "    plt.close(fig)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def run_dqn_csv(csv_data_path=\"full_data.csv\", episodes=5):\n",
        "    try:\n",
        "        df = pd.read_csv(csv_data_path, parse_dates=True, index_col=0)\n",
        "        if 'close' not in df.columns:\n",
        "            raise gr.Error(\"No 'close' column in CSV. Please ensure CSV has the necessary columns.\")\n",
        "        # Train the DQN\n",
        "        rewards_df, policy_net = train_dqn_from_df(df, episodes=episodes)\n",
        "\n",
        "        # Simulate day by day, logging every action\n",
        "        all_actions = simulate_dqn_trades(policy_net, df)\n",
        "\n",
        "        # Debug print so you can see all actions in console\n",
        "        print(\"=== DQN Actions Day by Day ===\")\n",
        "        for item in all_actions:\n",
        "            print(item)\n",
        "        print(\"================================\")\n",
        "\n",
        "        # Plot all actions\n",
        "        trade_plot = plot_trades_chart(df, all_actions)\n",
        "        return rewards_df, trade_plot\n",
        "    except Exception as e:\n",
        "        raise gr.Error(f\"An error occurred in the DQN module: {e}\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# 5) Gradio UI\n",
        "# ------------------------------------------------------------------------\n",
        "chart_interface = gr.Interface(\n",
        "    fn=generate_plot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ticker\", value=\"SPY\"),\n",
        "        gr.Textbox(label=\"Start Date (YYYY-MM-DD)\", value=default_start_date),\n",
        "        gr.Textbox(label=\"End Date (YYYY-MM-DD)\",   value=default_end_date),\n",
        "        gr.Slider(minimum=3, maximum=20, step=1, value=8,  label=\"n_period\"),\n",
        "        gr.Slider(minimum=3, maximum=20, step=1, value=13, label=\"r_period\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(type=\"pil\",   label=\"Chart\"),\n",
        "        gr.Dataframe(label=\"Current Indicator Status\"),\n",
        "        gr.Dataframe(label=\"Historical Signals\")\n",
        "    ],\n",
        "    title=\"Six-Panel Chart: ZLMA + RSI + Bressert + MCDX + MACD + VIX\",\n",
        "    description=(\n",
        "        \"Panel 1: Price candlestick with EMAs, ZLMA, RSI Trail.\\n\"\n",
        "        \"Panel 2: Bressert.\\n\"\n",
        "        \"Panel 3: MCDX (HBMA & signals).\\n\"\n",
        "        \"Panel 4: MCDX Bars.\\n\"\n",
        "        \"Panel 5: Zero Lag MACD.\\n\"\n",
        "        \"Panel 6: Implied Volatility (VIX).\\n\"\n",
        "        \"Outputs: Chart, Current Status, Historical Signals.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Tab(\"Chart\"):\n",
        "        chart_interface.render()\n",
        "\n",
        "    with gr.Tab(\"Save Data\"):\n",
        "        gr.Markdown(\"### Save Historical Data & Signals to CSV\")\n",
        "        with gr.Row():\n",
        "            sd_ticker  = gr.Textbox(label=\"Ticker\", value=\"SPY\")\n",
        "            sd_start   = gr.Textbox(label=\"Start Date\", value=default_start_date)\n",
        "            sd_end     = gr.Textbox(label=\"End Date\",   value=default_end_date)\n",
        "        with gr.Row():\n",
        "            sd_n   = gr.Slider(minimum=3,  maximum=20, step=1, value=8,  label=\"n_period\")\n",
        "            sd_r   = gr.Slider(minimum=3,  maximum=20, step=1, value=13, label=\"r_period\")\n",
        "        with gr.Row():\n",
        "            data_csv_path    = gr.Textbox(label=\"Data CSV Filename\",    value=\"full_data.csv\")\n",
        "            signals_csv_path = gr.Textbox(label=\"Signals CSV Filename\", value=\"signals_data.csv\")\n",
        "        btn_save = gr.Button(\"Save to CSV\")\n",
        "        save_output_msg = gr.Markdown()\n",
        "        def save_data_wrapper(ticker, start, end, n, r, datafile, sigfile):\n",
        "            return save_historical_data(ticker, start, end, n, r, datafile, sigfile)\n",
        "        btn_save.click(\n",
        "            fn=save_data_wrapper,\n",
        "            inputs=[sd_ticker, sd_start, sd_end, sd_n, sd_r, data_csv_path, signals_csv_path],\n",
        "            outputs=save_output_msg\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"DQN Training\"):\n",
        "        gr.Markdown(\"### Train DQN from Saved CSV\")\n",
        "        csv_input = gr.Textbox(label=\"CSV file path\", value=\"full_data.csv\", info=\"Path to the CSV with price data, as saved in the previous tab.\")\n",
        "        episodes_input = gr.Slider(label=\"Episodes\", value=5, minimum=1, maximum=200, step=1)\n",
        "        run_dqn_btn = gr.Button(\"Train DQN & Show Trades\")\n",
        "        dqn_rewards_out = gr.Dataframe(label=\"Episode Rewards\")\n",
        "        dqn_tradeplot_out = gr.Image(type=\"pil\", label=\"DQN Trades Chart\")\n",
        "        run_dqn_btn.click(\n",
        "            fn=run_dqn_csv,\n",
        "            inputs=[csv_input, episodes_input],\n",
        "            outputs=[dqn_rewards_out, dqn_tradeplot_out]\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "4xEOCh0iRcKL",
        "outputId": "43541ca1-937a-4cfc-be38-283ce389e538"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://48bec4c85de7e571a3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://48bec4c85de7e571a3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}