{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Based Trading Model Training\n",
    "\n",
    "This notebook trains a neural network model that incorporates news sentiment as a feature for predicting stock price movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest, StockLatestQuoteRequest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import time\n",
    "\n",
    "from trading_bot_llm_sentiment_brian import TradingBotLLMSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-29 07:44:52,177 - trading_bot_llm_sentiment_brian - INFO - Trading bot trading_bot_llm_sentiment_brian initialized with symbols: ['AAPL', 'MSFT', 'META', 'GOOGL', 'AMZN', 'NVDA']\n",
      "Bot initialized with symbols: ['AAPL', 'MSFT', 'META', 'GOOGL', 'AMZN', 'NVDA']\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Initialize the trading bot to use its data collection methods\n",
    "bot = TradingBotLLMSentiment()\n",
    "print(f\"Bot initialized with symbols: {bot.symbols}\")\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=365\n",
    "symbols = ['AAPL', 'MSFT', 'META', 'GOOGL', 'AMZN', 'NVDA']\n",
    "\n",
    "symbol = 'AAPL'\n",
    "filename = 'combined_historical_with_daily_sentiment.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['ALPACA_API_KEY']\n",
    "api_secret = os.environ['ALPACA_API_SECRET']\n",
    "data_client = StockHistoricalDataClient(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-27 21:29:53,934 - trading_bot_llm_sentiment_brian - INFO - Retrieved 250 bars for AAPL\n"
     ]
    }
   ],
   "source": [
    "df = bot.get_historical_data(symbol, days=days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-03-17 04:00:00+00:00</td>\n",
       "      <td>213.31</td>\n",
       "      <td>215.2200</td>\n",
       "      <td>209.97</td>\n",
       "      <td>214.00</td>\n",
       "      <td>48073426.0</td>\n",
       "      <td>577436.0</td>\n",
       "      <td>213.202242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-03-18 04:00:00+00:00</td>\n",
       "      <td>214.16</td>\n",
       "      <td>215.1500</td>\n",
       "      <td>211.49</td>\n",
       "      <td>212.69</td>\n",
       "      <td>42432426.0</td>\n",
       "      <td>493004.0</td>\n",
       "      <td>213.109470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-03-19 04:00:00+00:00</td>\n",
       "      <td>214.22</td>\n",
       "      <td>218.7600</td>\n",
       "      <td>213.75</td>\n",
       "      <td>215.24</td>\n",
       "      <td>54385391.0</td>\n",
       "      <td>524678.0</td>\n",
       "      <td>215.609629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-03-20 04:00:00+00:00</td>\n",
       "      <td>213.99</td>\n",
       "      <td>217.4899</td>\n",
       "      <td>212.22</td>\n",
       "      <td>214.10</td>\n",
       "      <td>48862947.0</td>\n",
       "      <td>499769.0</td>\n",
       "      <td>214.396693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-03-21 04:00:00+00:00</td>\n",
       "      <td>211.56</td>\n",
       "      <td>218.8400</td>\n",
       "      <td>211.28</td>\n",
       "      <td>218.27</td>\n",
       "      <td>94127768.0</td>\n",
       "      <td>496948.0</td>\n",
       "      <td>215.734078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                 timestamp    open      high     low   close  \\\n",
       "0   AAPL 2025-03-17 04:00:00+00:00  213.31  215.2200  209.97  214.00   \n",
       "1   AAPL 2025-03-18 04:00:00+00:00  214.16  215.1500  211.49  212.69   \n",
       "2   AAPL 2025-03-19 04:00:00+00:00  214.22  218.7600  213.75  215.24   \n",
       "3   AAPL 2025-03-20 04:00:00+00:00  213.99  217.4899  212.22  214.10   \n",
       "4   AAPL 2025-03-21 04:00:00+00:00  211.56  218.8400  211.28  218.27   \n",
       "\n",
       "       volume  trade_count        vwap  \n",
       "0  48073426.0     577436.0  213.202242  \n",
       "1  42432426.0     493004.0  213.109470  \n",
       "2  54385391.0     524678.0  215.609629  \n",
       "3  48862947.0     499769.0  214.396693  \n",
       "4  94127768.0     496948.0  215.734078  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_historical_data_with_daily_sentiment(symbol, days=365):\n",
    "    \"\"\"\n",
    "    Collect historical price data and daily sentiment data for a given symbol.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Stock symbol.\n",
    "        days (int): Number of days of historical data to collect.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Combined price and sentiment data.\n",
    "    \"\"\"\n",
    "    print(f\"Collecting data for {symbol}...\")\n",
    "    \n",
    "    # Get historical price data\n",
    "    df = bot.get_historical_data(symbol, days=days)\n",
    "    if df is None:\n",
    "        print(f\"No historical data found for {symbol}\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract the date from the timestamp for daily grouping\n",
    "    df['date'] = pd.to_datetime(df['timestamp']).dt.date\n",
    "    daily_dates = df['date'].unique().tolist()\n",
    "    \n",
    "    print(f\"Collected {len(df)} price data points, calculating sentiment for {len(daily_dates)} days...\")\n",
    "    \n",
    "    # Add sentiment column\n",
    "    df['sentiment'] = np.nan\n",
    "    \n",
    "    # Get sentiment for each day\n",
    "    for date in daily_dates:\n",
    "        date_str = pd.to_datetime(date).strftime('%Y-%m-%d')\n",
    "        print(f\"Getting sentiment for {symbol} for {date_str}\")\n",
    "        \n",
    "        articles = 10\n",
    "        news_date = pd.to_datetime(date)\n",
    "        # Using a 1-day lookback range to fetch daily sentiment\n",
    "        lookback_range = timedelta(days=1)\n",
    "        \n",
    "        sentiment = bot.get_sentiment_signal(symbol, articles, news_date, lookback_range)\n",
    "        df.loc[df['date'] == date, 'sentiment'] = sentiment\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    # df = df.dropna()\n",
    "    \n",
    "    print(f\"Final dataset: {len(df)} rows for {symbol}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all symbols and save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List to store dataframes for each symbol\n",
    "dfs = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        data = collect_historical_data_with_daily_sentiment(symbol)\n",
    "        if data is not None:\n",
    "            # Optionally add a symbol column if you want a combined DF later\n",
    "            data['symbol'] = symbol  \n",
    "            \n",
    "            # Save individual CSV for each symbol\n",
    "            data.to_csv(f\"data/{symbol}_historical_with_daily_sentiment.csv\", index=False)\n",
    "            print(f\"Saved data for {symbol}\")\n",
    "            \n",
    "            # Append to our list for later combining\n",
    "            dfs.append(data)\n",
    "        else:\n",
    "            print(f\"No data found for {symbol}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symbol}: {e}\")\n",
    "\n",
    "# If you want a single combined DataFrame for all symbols:\n",
    "if dfs:\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df.to_csv(\"data/combined_historical_with_daily_sentiment.csv\", index=False)\n",
    "    print(\"Saved combined data for all symbols.\")\n",
    "else:\n",
    "    print(\"No data to combine.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 30  # use past 30 days\n",
    "FEATURES = ['open', 'high', 'low', 'close', 'volume', 'sentiment'] \n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Identify which features to scale (excluding sentiment which is already -1 to 1)\n",
    "FEATURES_TO_SCALE = ['open', 'high', 'low', 'close', 'volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_file = \"data/combined_historical_with_daily_sentiment.csv\"\n",
    "if not os.path.exists(combined_file):\n",
    "    raise FileNotFoundError(f\"{combined_file} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(combined_file, index_col=0)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(['symbol', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>2025-03-28 04:00:00+00:00</td>\n",
       "      <td>111.485</td>\n",
       "      <td>112.87</td>\n",
       "      <td>109.0701</td>\n",
       "      <td>109.67</td>\n",
       "      <td>229872549.0</td>\n",
       "      <td>1847538.0</td>\n",
       "      <td>110.119953</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp     open    high       low   close  \\\n",
       "symbol                                                                \n",
       "NVDA   2025-03-28 04:00:00+00:00  111.485  112.87  109.0701  109.67   \n",
       "\n",
       "             volume  trade_count        vwap        date  sentiment  \n",
       "symbol                                                               \n",
       "NVDA    229872549.0    1847538.0  110.119953  2025-03-28        0.7  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL',\n",
       "       'AAPL',\n",
       "       ...\n",
       "       'NVDA', 'NVDA', 'NVDA', 'NVDA', 'NVDA', 'NVDA', 'NVDA', 'NVDA', 'NVDA',\n",
       "       'NVDA'],\n",
       "      dtype='object', name='symbol', length=1512)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[FEATURES_TO_SCALE] = scaler.fit_transform(df[FEATURES_TO_SCALE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'scaler': scaler,\n",
    "        'features_to_scale': FEATURES_TO_SCALE\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2024-03-27 04:00:00+00:00</td>\n",
       "      <td>0.068224</td>\n",
       "      <td>0.060904</td>\n",
       "      <td>0.072695</td>\n",
       "      <td>0.066105</td>\n",
       "      <td>0.068231</td>\n",
       "      <td>670630.0</td>\n",
       "      <td>172.581734</td>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2024-03-28 04:00:00+00:00</td>\n",
       "      <td>0.069391</td>\n",
       "      <td>0.059716</td>\n",
       "      <td>0.073061</td>\n",
       "      <td>0.064479</td>\n",
       "      <td>0.074863</td>\n",
       "      <td>648027.0</td>\n",
       "      <td>171.355595</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2024-04-01 04:00:00+00:00</td>\n",
       "      <td>0.068903</td>\n",
       "      <td>0.058865</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.063190</td>\n",
       "      <td>0.050994</td>\n",
       "      <td>676830.0</td>\n",
       "      <td>170.066484</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2024-04-02 04:00:00+00:00</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>0.057208</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.054821</td>\n",
       "      <td>608917.0</td>\n",
       "      <td>168.895583</td>\n",
       "      <td>2024-04-02</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2024-04-03 04:00:00+00:00</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>0.058371</td>\n",
       "      <td>0.071295</td>\n",
       "      <td>0.062853</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>571286.0</td>\n",
       "      <td>169.864966</td>\n",
       "      <td>2024-04-03</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp      open      high       low     close  \\\n",
       "symbol                                                                     \n",
       "AAPL   2024-03-27 04:00:00+00:00  0.068224  0.060904  0.072695  0.066105   \n",
       "AAPL   2024-03-28 04:00:00+00:00  0.069391  0.059716  0.073061  0.064479   \n",
       "AAPL   2024-04-01 04:00:00+00:00  0.068903  0.058865  0.072114  0.063190   \n",
       "AAPL   2024-04-02 04:00:00+00:00  0.067066  0.057208  0.070974  0.062133   \n",
       "AAPL   2024-04-03 04:00:00+00:00  0.066814  0.058371  0.071295  0.062853   \n",
       "\n",
       "          volume  trade_count        vwap        date  sentiment  \n",
       "symbol                                                            \n",
       "AAPL    0.068231     670630.0  172.581734  2024-03-27        0.0  \n",
       "AAPL    0.074863     648027.0  171.355595  2024-03-28        0.0  \n",
       "AAPL    0.050994     676830.0  170.066484  2024-04-01       -0.7  \n",
       "AAPL    0.054821     608917.0  168.895583  2024-04-02       -0.5  \n",
       "AAPL    0.052777     571286.0  169.864966  2024-04-03       -0.3  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "symbol_dummies = pd.get_dummies(df['symbol'], prefix='symbol').astype('float32')\n",
    "df = pd.concat([df, symbol_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_columns = symbol_dummies.columns.tolist()\n",
    "all_features = FEATURES + symbol_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['open', 'high', 'low', 'close', 'volume', 'sentiment', 'symbol_AAPL', 'symbol_AMZN', 'symbol_GOOGL', 'symbol_META', 'symbol_MSFT', 'symbol_NVDA']\n"
     ]
    }
   ],
   "source": [
    "print(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, y_train_list = [], []\n",
    "X_test_list, y_test_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, seq_length=SEQ_LENGTH, feature_columns=all_features):\n",
    "    \"\"\"\n",
    "    Create sequences from the DataFrame using a sliding window.\n",
    "    For each sequence of past `seq_length` days, the target is the closing price on day seq_length+1.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    if len(df) < seq_length + 1:\n",
    "        return None, None\n",
    "    for i in range(len(df) - seq_length):\n",
    "        # Sequence of features for past seq_length days\n",
    "        seq = df.iloc[i:i+seq_length][feature_columns].values\n",
    "        # Target is next day's closing price\n",
    "        target = df.iloc[i+seq_length]['close']\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL: 222 sequences, 177 training samples and 45 testing samples.\n",
      "AMZN: 222 sequences, 177 training samples and 45 testing samples.\n",
      "GOOGL: 222 sequences, 177 training samples and 45 testing samples.\n",
      "META: 222 sequences, 177 training samples and 45 testing samples.\n",
      "MSFT: 222 sequences, 177 training samples and 45 testing samples.\n",
      "NVDA: 222 sequences, 177 training samples and 45 testing samples.\n"
     ]
    }
   ],
   "source": [
    "for symbol, group in df.groupby('symbol'):\n",
    "    group = group.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    X_symbol, y_symbol = create_sequences(group, seq_length=SEQ_LENGTH)\n",
    "    \n",
    "    if X_symbol is None or len(X_symbol) == 0:\n",
    "        print(f\"Not enough data for {symbol}; skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Split data by time (first TRAIN_RATIO for training, rest for testing)\n",
    "    split_idx = int(len(X_symbol) * TRAIN_RATIO)\n",
    "    X_train_list.append(X_symbol[:split_idx])\n",
    "    y_train_list.append(y_symbol[:split_idx])\n",
    "    X_test_list.append(X_symbol[split_idx:])\n",
    "    y_test_list.append(y_symbol[split_idx:])\n",
    "    \n",
    "    print(f\"{symbol}: {len(X_symbol)} sequences, {split_idx} training samples and {len(X_symbol) - split_idx} testing samples.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "X_test = np.concatenate(X_test_list, axis=0)\n",
    "y_test = np.concatenate(y_test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training shape: (1062, 30, 12)\n",
      "Combined testing shape: (270, 30, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined training shape:\", X_train.shape)\n",
    "print(\"Combined testing shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I523193/.local/pipx/venvs/jupyter/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m72,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,657</span> (479.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,657\u001b[0m (479.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,657</span> (479.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,657\u001b[0m (479.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(SEQ_LENGTH, num_features)))\n",
    "model.add(Dropout(0.2))  # Dropout to reduce overfitting\n",
    "\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# An intermediate dense layer\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Final output layer for regression\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 37130.2070 - val_loss: 116.6497 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 29.7888 - val_loss: 45.8966 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 17.1469 - val_loss: 41.3592 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 14.4220 - val_loss: 37.3454 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.8938 - val_loss: 16.9801 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.9328 - val_loss: 5.8792 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.1208 - val_loss: 2.8102 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.3311 - val_loss: 1.7059 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9499 - val_loss: 1.1774 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.6802 - val_loss: 0.8778 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.5193 - val_loss: 0.6783 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3626 - val_loss: 0.4787 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.2091 - val_loss: 0.2951 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1058 - val_loss: 0.1821 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0556 - val_loss: 0.1277 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0377 - val_loss: 0.1015 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0278 - val_loss: 0.0870 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0247 - val_loss: 0.0774 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0222 - val_loss: 0.0730 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0195 - val_loss: 0.0702 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0167 - val_loss: 0.0656 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0134 - val_loss: 0.0593 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0112 - val_loss: 0.0525 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0084 - val_loss: 0.0479 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0061 - val_loss: 0.0452 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0048 - val_loss: 0.0432 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0055 - val_loss: 0.0422 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0410 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0414 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - val_loss: 0.0410 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0409 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - val_loss: 0.0410 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 0.0410 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0031 - val_loss: 0.0408 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 0.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 0.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0024 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 0.0422 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 0.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0421 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 0.0422 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 0.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0424 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0024 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0017 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 0.0424 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0424 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0426 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0425 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 0.0437 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0014 - val_loss: 0.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0437 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.6503e-04 - val_loss: 0.0443 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0441 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0445 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0447 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0444 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0442 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0433 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 0.0445 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0442 - learning_rate: 1.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0010 - val_loss: 0.0450 - learning_rate: 1.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0451 - learning_rate: 1.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.8698e-04 - val_loss: 0.0443 - learning_rate: 1.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0458 - learning_rate: 1.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 9.0548e-04 - val_loss: 0.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0457 - learning_rate: 1.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 0.0442 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100, batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015\n",
      "Test Loss (MSE): 0.0027952813543379307\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss (MSE):\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-29\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now().strftime('%Y-%m-%d')\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LSTM model to models/lstm_combined_model_2025-03-29.keras\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/models', exist_ok=True)\n",
    "date = datetime.now().strftime('%Y-%m-%d')\n",
    "path = 'data'\n",
    "model_name = f\"lstm_combined_model_{date}.keras\"\n",
    "model.save(f\"data/models/{model_name}\")\n",
    "print(f\"Saved LSTM model to models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_todays_closing_price_enriched(symbol):\n",
    "    \"\"\"\n",
    "    Predict today's closing price for the given symbol using enriched price data that includes sentiment.\n",
    "    \n",
    "    Process:\n",
    "    1. Load and update historical sentiment data.\n",
    "    2. Scale the price and volume features (same as during training).\n",
    "    3. Add one-hot encoding for symbols.\n",
    "    4. Create the input sequence for the model.\n",
    "    5. Predict the closing price.\n",
    "    \n",
    "    Returns:\n",
    "        float or None: The predicted closing price for today, or None if not enough data.\n",
    "    \"\"\"\n",
    "    # Load the scaler\n",
    "    with open('data/scaler.pkl', 'rb') as f:\n",
    "        scaler_info = pickle.load(f)\n",
    "        SCALER = scaler_info['scaler']\n",
    "        FEATURES_TO_SCALE = scaler_info['features_to_scale']\n",
    "    \n",
    "    # Load the trained model\n",
    "    MODEL = load_model(f\"data/models/lstm_combined_model_2025-03-29.keras\")\n",
    "    \n",
    "    # Step 1: Load and update historical sentiment data\n",
    "    df = bot.load_and_update_sentiment_data(SEQ_LENGTH)\n",
    "    if df is None or df.empty:\n",
    "        print(\"Failed to load sentiment data.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Scale numerical features using the same scaler from training\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[FEATURES_TO_SCALE] = SCALER.transform(df[FEATURES_TO_SCALE])\n",
    "    \n",
    "    # Step 3: Add one-hot encoding for symbols\n",
    "    symbol_dummies = pd.get_dummies(df_scaled['symbol'], prefix='symbol').astype('float32')\n",
    "    df_scaled = pd.concat([df_scaled, symbol_dummies], axis=1)\n",
    "    \n",
    "    # Get the full list of features for the model\n",
    "    symbol_columns = [col for col in df_scaled.columns if col.startswith('symbol_')]\n",
    "    all_features = FEATURES + symbol_columns\n",
    "    \n",
    "    # Step 4: Filter for the specific symbol and check data sufficiency\n",
    "    symbol_df = df_scaled[df_scaled['symbol'] == symbol].sort_values(by=\"timestamp\")\n",
    "    if len(symbol_df) < SEQ_LENGTH:\n",
    "        print(f\"Not enough data for {symbol}. Need {SEQ_LENGTH} days, have {len(symbol_df)}.\")\n",
    "        return None\n",
    "    \n",
    "    # Create input sequence using the last SEQ_LENGTH rows\n",
    "    input_seq = symbol_df.iloc[-SEQ_LENGTH:][all_features].values.astype('float32')\n",
    "    input_seq = input_seq.reshape(1, SEQ_LENGTH, len(all_features))\n",
    "    \n",
    "    # Step 5: Make the prediction (scaled)\n",
    "    predicted_scaled = MODEL.predict(input_seq, verbose=0)[0][0]\n",
    "    \n",
    "    # Step 6: Unscale the prediction\n",
    "    # Get the index of 'close' in FEATURES_TO_SCALE\n",
    "    close_idx = FEATURES_TO_SCALE.index('close')\n",
    "    \n",
    "    # Create a dummy array with zeros for all scalable features\n",
    "    dummy = np.zeros((1, len(FEATURES_TO_SCALE)))\n",
    "    # Place the scaled prediction in the position corresponding to 'close'\n",
    "    dummy[0, close_idx] = predicted_scaled\n",
    "    \n",
    "    # Inverse transform to get the actual price\n",
    "    unscaled_dummy = SCALER.inverse_transform(dummy)\n",
    "    # Extract the unscaled closing price\n",
    "    predicted_price = unscaled_dummy[0, close_idx]    \n",
    "    print(f\"Predicted closing price for {symbol} is ${predicted_price:.2f}\")\n",
    "    \n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'NVDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-29 16:21:58,181 - trading_bot_llm_sentiment_brian - INFO - Loaded combined historical data from data/combined_historical_with_daily_sentiment.csv\n",
      "2025-03-29 16:21:58,275 - trading_bot_llm_sentiment_brian - INFO - Retrieved 21 bars for AAPL\n",
      "2025-03-29 16:21:58,373 - trading_bot_llm_sentiment_brian - INFO - Retrieved 21 bars for MSFT\n",
      "2025-03-29 16:21:58,480 - trading_bot_llm_sentiment_brian - INFO - Retrieved 21 bars for META\n",
      "2025-03-29 16:21:58,592 - trading_bot_llm_sentiment_brian - INFO - Retrieved 21 bars for GOOGL\n",
      "2025-03-29 16:21:58,694 - trading_bot_llm_sentiment_brian - INFO - Retrieved 21 bars for AMZN\n",
      "2025-03-29 16:21:58,804 - trading_bot_llm_sentiment_brian - INFO - Retrieved 21 bars for NVDA\n",
      "2025-03-29 16:21:58,808 - trading_bot_llm_sentiment_brian - INFO - Combined historical data is up-to-date.\n",
      "Predicted closing price for NVDA is $209.35\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_todays_closing_price_enriched(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
